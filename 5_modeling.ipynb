{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "from pretrained_model import *\n",
        "from mmseg.registry import DATASETS\n",
        "from mmseg.datasets import *\n",
        "%cd mmsegmentation\n",
        "\n",
        "root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
        "img_dir = 'image_png_256_gray'\n",
        "ann_dir = 'fluid_png_256_binary'\n",
        "\n",
        "classes = ('image', 'fluid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "@DATASETS.register_module()\n",
        "class BOE_Chiu_Dataset(BaseSegDataset):\n",
        "    METAINFO = dict(classes = classes)\n",
        "    def __init__(self,dataset=None, times=None, **kwargs):\n",
        "        super(BOE_Chiu_Dataset, self).__init__(img_suffix='.png', seg_map_suffix='.png', **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. UNET with FCN Head Pretrained on HRF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_fcn_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:17:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/15 21:17:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/15 21:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:17:15 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth\n",
            "12/15 21:17:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth\n",
            "12/15 21:17:16 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/15 21:17:16 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "12/15 21:17:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/15 21:17:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:02:41  time: 0.8478  data_time: 0.0048  memory: 10544  loss: 0.1018  decode.loss_ce: 0.0732  decode.acc_seg: 98.5847  aux.loss_ce: 0.0286  aux.acc_seg: 98.5847\n",
            "12/15 21:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:33  time: 0.1879  data_time: 0.0046  memory: 4703  loss: 0.0573  decode.loss_ce: 0.0405  decode.acc_seg: 99.4789  aux.loss_ce: 0.0168  aux.acc_seg: 99.4789\n",
            "12/15 21:17:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:01:09  time: 0.1876  data_time: 0.0045  memory: 4703  loss: 0.0521  decode.loss_ce: 0.0371  decode.acc_seg: 99.9313  aux.loss_ce: 0.0150  aux.acc_seg: 99.9313\n",
            "12/15 21:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:00:56  time: 0.1881  data_time: 0.0046  memory: 4703  loss: 0.0345  decode.loss_ce: 0.0237  decode.acc_seg: 98.6740  aux.loss_ce: 0.0108  aux.acc_seg: 98.6740\n",
            "12/15 21:17:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_fcn_4xb4-40k_hrf-256x256_20231215_211711\n",
            "12/15 21:17:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:00:47  time: 0.1877  data_time: 0.0046  memory: 4703  loss: 0.0267  decode.loss_ce: 0.0176  decode.acc_seg: 98.1880  aux.loss_ce: 0.0092  aux.acc_seg: 98.1880\n",
            "12/15 21:17:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:00:41  time: 0.1896  data_time: 0.0048  memory: 4703  loss: 0.0331  decode.loss_ce: 0.0227  decode.acc_seg: 99.3599  aux.loss_ce: 0.0104  aux.acc_seg: 99.3599\n",
            "12/15 21:17:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:00:36  time: 0.1874  data_time: 0.0047  memory: 4703  loss: 0.0250  decode.loss_ce: 0.0168  decode.acc_seg: 99.9016  aux.loss_ce: 0.0083  aux.acc_seg: 99.9016\n",
            "12/15 21:17:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:32  time: 0.1897  data_time: 0.0045  memory: 4703  loss: 0.0251  decode.loss_ce: 0.0171  decode.acc_seg: 100.0000  aux.loss_ce: 0.0080  aux.acc_seg: 100.0000\n",
            "12/15 21:17:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:28  time: 0.1884  data_time: 0.0045  memory: 4703  loss: 0.0297  decode.loss_ce: 0.0203  decode.acc_seg: 99.4537  aux.loss_ce: 0.0094  aux.acc_seg: 99.3172\n",
            "12/15 21:17:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:25  time: 0.1878  data_time: 0.0045  memory: 4703  loss: 0.0266  decode.loss_ce: 0.0181  decode.acc_seg: 99.7860  aux.loss_ce: 0.0085  aux.acc_seg: 99.6452\n",
            "12/15 21:17:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:22  time: 0.1889  data_time: 0.0046  memory: 4703  loss: 0.0246  decode.loss_ce: 0.0165  decode.acc_seg: 99.8535  aux.loss_ce: 0.0080  aux.acc_seg: 99.7719\n",
            "12/15 21:17:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:19  time: 0.1885  data_time: 0.0045  memory: 4703  loss: 0.0177  decode.loss_ce: 0.0115  decode.acc_seg: 99.7534  aux.loss_ce: 0.0061  aux.acc_seg: 99.5880\n",
            "12/15 21:17:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:16  time: 0.1869  data_time: 0.0045  memory: 4703  loss: 0.0193  decode.loss_ce: 0.0128  decode.acc_seg: 99.8835  aux.loss_ce: 0.0065  aux.acc_seg: 99.8413\n",
            "12/15 21:17:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:14  time: 0.1875  data_time: 0.0045  memory: 4703  loss: 0.0206  decode.loss_ce: 0.0137  decode.acc_seg: 99.5817  aux.loss_ce: 0.0069  aux.acc_seg: 99.1989\n",
            "12/15 21:17:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:11  time: 0.1885  data_time: 0.0046  memory: 4703  loss: 0.0215  decode.loss_ce: 0.0144  decode.acc_seg: 99.6161  aux.loss_ce: 0.0071  aux.acc_seg: 99.4392\n",
            "12/15 21:17:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:09  time: 0.1895  data_time: 0.0049  memory: 4703  loss: 0.0249  decode.loss_ce: 0.0168  decode.acc_seg: 99.3126  aux.loss_ce: 0.0081  aux.acc_seg: 98.7350\n",
            "12/15 21:17:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:06  time: 0.1894  data_time: 0.0048  memory: 4703  loss: 0.0180  decode.loss_ce: 0.0121  decode.acc_seg: 99.9207  aux.loss_ce: 0.0059  aux.acc_seg: 99.8711\n",
            "12/15 21:17:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:04  time: 0.1876  data_time: 0.0047  memory: 4703  loss: 0.0153  decode.loss_ce: 0.0103  decode.acc_seg: 99.5863  aux.loss_ce: 0.0050  aux.acc_seg: 99.4888\n",
            "12/15 21:17:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:02  time: 0.1895  data_time: 0.0056  memory: 4703  loss: 0.0138  decode.loss_ce: 0.0090  decode.acc_seg: 99.9506  aux.loss_ce: 0.0048  aux.acc_seg: 99.8825\n",
            "12/15 21:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.1899  data_time: 0.0048  memory: 4703  loss: 0.0305  decode.loss_ce: 0.0211  decode.acc_seg: 99.9897  aux.loss_ce: 0.0094  aux.acc_seg: 100.0000\n",
            "12/15 21:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/15 21:18:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:03  time: 0.3170  data_time: 0.0142  memory: 9011  \n",
            "12/15 21:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1224  data_time: 0.0025  memory: 372  \n",
            "12/15 21:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/15 21:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.65 | 99.83 | 99.29 | 99.65  |   99.46   | 99.83  |\n",
            "| fluid |  48.0 |  37.7 | 31.58 |  48.0  |   66.04   |  37.7  |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/15 21:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.3000  mDice: 73.8200  mAcc: 68.7700  mIoU: 65.4400  mFscore: 73.8200  mPrecision: 82.7500  mRecall: 68.7700  data_time: 0.0079  time: 0.2111\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_fcn_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. UNET with PSPNet Head Pretrained on HRF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_pspnet_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:18:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=16,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        pool_scales=(\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "            6,\n",
            "        ),\n",
            "        type='PSPHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:18:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/15 21:18:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:18:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth\n",
            "12/15 21:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth\n",
            "12/15 21:18:49 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/15 21:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/15 21:18:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:01:42  time: 0.5380  data_time: 0.0050  memory: 9486  loss: 0.1036  decode.loss_ce: 0.0740  decode.acc_seg: 98.5847  aux.loss_ce: 0.0296  aux.acc_seg: 98.5847\n",
            "12/15 21:19:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:30  time: 0.4672  data_time: 0.0051  memory: 4478  loss: 0.0599  decode.loss_ce: 0.0411  decode.acc_seg: 99.4789  aux.loss_ce: 0.0188  aux.acc_seg: 99.4789\n",
            "12/15 21:19:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:01:23  time: 0.4668  data_time: 0.0050  memory: 4478  loss: 0.0522  decode.loss_ce: 0.0353  decode.acc_seg: 99.9313  aux.loss_ce: 0.0168  aux.acc_seg: 99.9313\n",
            "12/15 21:19:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:01:17  time: 0.4680  data_time: 0.0050  memory: 4478  loss: 0.0393  decode.loss_ce: 0.0273  decode.acc_seg: 98.6710  aux.loss_ce: 0.0120  aux.acc_seg: 98.6740\n",
            "12/15 21:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_pspnet_4xb4-40k_hrf-256x256_20231215_211806\n",
            "12/15 21:19:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:01:12  time: 0.4691  data_time: 0.0052  memory: 4478  loss: 0.0274  decode.loss_ce: 0.0188  decode.acc_seg: 98.5140  aux.loss_ce: 0.0087  aux.acc_seg: 98.1880\n",
            "12/15 21:19:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:01:07  time: 0.4672  data_time: 0.0053  memory: 4478  loss: 0.0346  decode.loss_ce: 0.0243  decode.acc_seg: 99.1385  aux.loss_ce: 0.0103  aux.acc_seg: 99.4261\n",
            "12/15 21:19:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:01:02  time: 0.4674  data_time: 0.0049  memory: 4478  loss: 0.0253  decode.loss_ce: 0.0170  decode.acc_seg: 99.9016  aux.loss_ce: 0.0084  aux.acc_seg: 99.9016\n",
            "12/15 21:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:57  time: 0.4675  data_time: 0.0050  memory: 4478  loss: 0.0257  decode.loss_ce: 0.0168  decode.acc_seg: 100.0000  aux.loss_ce: 0.0089  aux.acc_seg: 100.0000\n",
            "12/15 21:19:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:52  time: 0.4673  data_time: 0.0050  memory: 4478  loss: 0.0281  decode.loss_ce: 0.0190  decode.acc_seg: 99.4209  aux.loss_ce: 0.0092  aux.acc_seg: 99.3965\n",
            "12/15 21:19:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:47  time: 0.4673  data_time: 0.0048  memory: 4478  loss: 0.0253  decode.loss_ce: 0.0172  decode.acc_seg: 99.6922  aux.loss_ce: 0.0081  aux.acc_seg: 99.7604\n",
            "12/15 21:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:42  time: 0.4669  data_time: 0.0050  memory: 4478  loss: 0.0231  decode.loss_ce: 0.0153  decode.acc_seg: 99.8266  aux.loss_ce: 0.0079  aux.acc_seg: 99.8415\n",
            "12/15 21:19:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:37  time: 0.4673  data_time: 0.0048  memory: 4478  loss: 0.0161  decode.loss_ce: 0.0104  decode.acc_seg: 99.8381  aux.loss_ce: 0.0057  aux.acc_seg: 99.8110\n",
            "12/15 21:19:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:33  time: 0.4670  data_time: 0.0050  memory: 4478  loss: 0.0163  decode.loss_ce: 0.0105  decode.acc_seg: 99.8934  aux.loss_ce: 0.0057  aux.acc_seg: 99.8917\n",
            "12/15 21:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:28  time: 0.4679  data_time: 0.0049  memory: 4478  loss: 0.0187  decode.loss_ce: 0.0123  decode.acc_seg: 99.6120  aux.loss_ce: 0.0064  aux.acc_seg: 99.7025\n",
            "12/15 21:20:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:23  time: 0.4696  data_time: 0.0056  memory: 4478  loss: 0.0187  decode.loss_ce: 0.0122  decode.acc_seg: 99.6357  aux.loss_ce: 0.0065  aux.acc_seg: 99.6065\n",
            "12/15 21:20:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:18  time: 0.4667  data_time: 0.0049  memory: 4478  loss: 0.0218  decode.loss_ce: 0.0149  decode.acc_seg: 99.5001  aux.loss_ce: 0.0069  aux.acc_seg: 99.4640\n",
            "12/15 21:20:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:14  time: 0.4673  data_time: 0.0050  memory: 4478  loss: 0.0158  decode.loss_ce: 0.0103  decode.acc_seg: 99.9428  aux.loss_ce: 0.0055  aux.acc_seg: 99.9363\n",
            "12/15 21:20:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:09  time: 0.4688  data_time: 0.0051  memory: 4478  loss: 0.0134  decode.loss_ce: 0.0084  decode.acc_seg: 99.6468  aux.loss_ce: 0.0050  aux.acc_seg: 99.6407\n",
            "12/15 21:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:04  time: 0.4680  data_time: 0.0050  memory: 4478  loss: 0.0114  decode.loss_ce: 0.0072  decode.acc_seg: 99.9218  aux.loss_ce: 0.0041  aux.acc_seg: 99.9168\n",
            "12/15 21:20:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.4688  data_time: 0.0050  memory: 4478  loss: 0.0248  decode.loss_ce: 0.0168  decode.acc_seg: 100.0000  aux.loss_ce: 0.0080  aux.acc_seg: 100.0000\n",
            "12/15 21:20:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/15 21:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.1799  data_time: 0.0130  memory: 1592  \n",
            "12/15 21:20:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1504  data_time: 0.0026  memory: 394  \n",
            "12/15 21:20:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/15 21:20:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.63 | 99.84 | 99.27 | 99.63  |   99.43   | 99.84  |\n",
            "| fluid | 44.91 | 34.33 | 28.95 | 44.91  |   64.91   | 34.33  |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/15 21:20:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.2700  mDice: 72.2700  mAcc: 67.0800  mIoU: 64.1100  mFscore: 72.2700  mPrecision: 82.1700  mRecall: 67.0800  data_time: 0.0073  time: 0.1638\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_pspnet_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. UNET with DeepLabV3 Pretrained on HRF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:20:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:21:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=16,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='ASPPHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/15 21:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:21:11 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth\n",
            "12/15 21:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth\n",
            "12/15 21:21:12 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/15 21:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/15 21:21:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:01:26  time: 0.4545  data_time: 0.0047  memory: 7822  loss: 0.1127  decode.loss_ce: 0.0803  decode.acc_seg: 98.5847  aux.loss_ce: 0.0324  aux.acc_seg: 98.5847\n",
            "12/15 21:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:08  time: 0.3044  data_time: 0.0051  memory: 4643  loss: 0.0608  decode.loss_ce: 0.0416  decode.acc_seg: 99.4593  aux.loss_ce: 0.0192  aux.acc_seg: 99.4789\n",
            "12/15 21:21:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:01:00  time: 0.3033  data_time: 0.0052  memory: 4643  loss: 0.0532  decode.loss_ce: 0.0356  decode.acc_seg: 99.8783  aux.loss_ce: 0.0176  aux.acc_seg: 99.9313\n",
            "12/15 21:21:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:00:54  time: 0.3038  data_time: 0.0056  memory: 4643  loss: 0.0375  decode.loss_ce: 0.0257  decode.acc_seg: 98.6132  aux.loss_ce: 0.0118  aux.acc_seg: 98.6740\n",
            "12/15 21:21:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256_20231215_212029\n",
            "12/15 21:21:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:00:50  time: 0.3036  data_time: 0.0050  memory: 4643  loss: 0.0303  decode.loss_ce: 0.0216  decode.acc_seg: 98.1880  aux.loss_ce: 0.0087  aux.acc_seg: 98.1880\n",
            "12/15 21:21:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:00:46  time: 0.3031  data_time: 0.0049  memory: 4643  loss: 0.0342  decode.loss_ce: 0.0239  decode.acc_seg: 99.2373  aux.loss_ce: 0.0102  aux.acc_seg: 99.3649\n",
            "12/15 21:21:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:00:42  time: 0.3038  data_time: 0.0049  memory: 4643  loss: 0.0256  decode.loss_ce: 0.0172  decode.acc_seg: 99.9012  aux.loss_ce: 0.0084  aux.acc_seg: 99.9016\n",
            "12/15 21:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:38  time: 0.3035  data_time: 0.0050  memory: 4643  loss: 0.0257  decode.loss_ce: 0.0172  decode.acc_seg: 100.0000  aux.loss_ce: 0.0085  aux.acc_seg: 99.9931\n",
            "12/15 21:21:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:35  time: 0.3026  data_time: 0.0049  memory: 4643  loss: 0.0290  decode.loss_ce: 0.0196  decode.acc_seg: 99.3742  aux.loss_ce: 0.0095  aux.acc_seg: 99.4743\n",
            "12/15 21:21:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:31  time: 0.3028  data_time: 0.0049  memory: 4643  loss: 0.0279  decode.loss_ce: 0.0195  decode.acc_seg: 99.8251  aux.loss_ce: 0.0084  aux.acc_seg: 99.8281\n",
            "12/15 21:21:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:28  time: 0.3044  data_time: 0.0050  memory: 4643  loss: 0.0228  decode.loss_ce: 0.0153  decode.acc_seg: 99.7065  aux.loss_ce: 0.0076  aux.acc_seg: 99.8257\n",
            "12/15 21:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:25  time: 0.3026  data_time: 0.0048  memory: 4643  loss: 0.0160  decode.loss_ce: 0.0103  decode.acc_seg: 99.8470  aux.loss_ce: 0.0057  aux.acc_seg: 99.8091\n",
            "12/15 21:21:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:22  time: 0.3023  data_time: 0.0049  memory: 4643  loss: 0.0172  decode.loss_ce: 0.0110  decode.acc_seg: 99.9023  aux.loss_ce: 0.0063  aux.acc_seg: 99.8844\n",
            "12/15 21:21:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:18  time: 0.3030  data_time: 0.0050  memory: 4643  loss: 0.0193  decode.loss_ce: 0.0128  decode.acc_seg: 99.6422  aux.loss_ce: 0.0065  aux.acc_seg: 99.5392\n",
            "12/15 21:21:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:15  time: 0.3040  data_time: 0.0050  memory: 4643  loss: 0.0192  decode.loss_ce: 0.0126  decode.acc_seg: 99.6670  aux.loss_ce: 0.0066  aux.acc_seg: 99.6546\n",
            "12/15 21:22:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:12  time: 0.3025  data_time: 0.0052  memory: 4643  loss: 0.0218  decode.loss_ce: 0.0150  decode.acc_seg: 99.5056  aux.loss_ce: 0.0069  aux.acc_seg: 99.4783\n",
            "12/15 21:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:09  time: 0.3029  data_time: 0.0054  memory: 4643  loss: 0.0161  decode.loss_ce: 0.0105  decode.acc_seg: 99.9369  aux.loss_ce: 0.0056  aux.acc_seg: 99.9294\n",
            "12/15 21:22:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:06  time: 0.3043  data_time: 0.0048  memory: 4643  loss: 0.0138  decode.loss_ce: 0.0087  decode.acc_seg: 99.6435  aux.loss_ce: 0.0050  aux.acc_seg: 99.6132\n",
            "12/15 21:22:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:03  time: 0.3030  data_time: 0.0048  memory: 4643  loss: 0.0121  decode.loss_ce: 0.0077  decode.acc_seg: 99.9201  aux.loss_ce: 0.0044  aux.acc_seg: 99.9260\n",
            "12/15 21:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.3018  data_time: 0.0048  memory: 4643  loss: 0.0243  decode.loss_ce: 0.0164  decode.acc_seg: 99.9971  aux.loss_ce: 0.0079  aux.acc_seg: 99.9985\n",
            "12/15 21:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/15 21:22:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.1695  data_time: 0.0133  memory: 1151  \n",
            "12/15 21:22:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1436  data_time: 0.0025  memory: 396  \n",
            "12/15 21:22:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/15 21:22:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.66 | 99.89 | 99.33 | 99.66  |   99.44   | 99.89  |\n",
            "| fluid |  47.6 | 35.16 | 31.24 |  47.6  |   73.66   | 35.16  |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/15 21:22:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.3300  mDice: 73.6300  mAcc: 67.5300  mIoU: 65.2800  mFscore: 73.6300  mPrecision: 86.5500  mRecall: 67.5300  data_time: 0.0074  time: 0.1554\n"
          ]
        }
      ],
      "source": [
        "\n",
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. PSPNET Pretrained on Postdam Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config pspnet_r50-d8_4xb4-80k_potsdam-512x512 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:22:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:22:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=512,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        pool_scales=(\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "            6,\n",
            "        ),\n",
            "        type='PSPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=80000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/15 21:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:23:01 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "12/15 21:23:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet50_v1c\n",
            "12/15 21:23:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n",
            "12/15 21:23:02 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([6, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 512, 1, 1]).\n",
            "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([6, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).\n",
            "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/15 21:23:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth\n",
            "12/15 21:23:02 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/15 21:23:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/15 21:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9990e-03  eta: 0:03:54  time: 1.2323  data_time: 0.0052  memory: 11248  loss: 0.6168  decode.loss_ce: 0.3929  decode.acc_seg: 98.5847  aux.loss_ce: 0.2239  aux.acc_seg: 98.5847\n",
            "12/15 21:23:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9979e-03  eta: 0:02:14  time: 0.2596  data_time: 0.0054  memory: 3340  loss: 0.1268  decode.loss_ce: 0.0523  decode.acc_seg: 99.4789  aux.loss_ce: 0.0744  aux.acc_seg: 99.4789\n",
            "12/15 21:23:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9968e-03  eta: 0:01:39  time: 0.2580  data_time: 0.0056  memory: 3340  loss: 0.0584  decode.loss_ce: 0.0271  decode.acc_seg: 99.9313  aux.loss_ce: 0.0313  aux.acc_seg: 99.9313\n",
            "12/15 21:23:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9957e-03  eta: 0:01:20  time: 0.2586  data_time: 0.0052  memory: 3340  loss: 0.0355  decode.loss_ce: 0.0174  decode.acc_seg: 98.6740  aux.loss_ce: 0.0181  aux.acc_seg: 98.6740\n",
            "12/15 21:23:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: pspnet_r50-d8_4xb4-80k_potsdam-512x512_20231215_212219\n",
            "12/15 21:23:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9945e-03  eta: 0:01:07  time: 0.2573  data_time: 0.0053  memory: 3340  loss: 0.0287  decode.loss_ce: 0.0159  decode.acc_seg: 98.1880  aux.loss_ce: 0.0128  aux.acc_seg: 98.1880\n",
            "12/15 21:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9934e-03  eta: 0:00:58  time: 0.2569  data_time: 0.0059  memory: 3340  loss: 0.0344  decode.loss_ce: 0.0203  decode.acc_seg: 99.3599  aux.loss_ce: 0.0142  aux.acc_seg: 99.3599\n",
            "12/15 21:23:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9923e-03  eta: 0:00:51  time: 0.2565  data_time: 0.0051  memory: 3340  loss: 0.0260  decode.loss_ce: 0.0153  decode.acc_seg: 99.9016  aux.loss_ce: 0.0107  aux.acc_seg: 99.9016\n",
            "12/15 21:23:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9912e-03  eta: 0:00:45  time: 0.2566  data_time: 0.0053  memory: 3340  loss: 0.0234  decode.loss_ce: 0.0136  decode.acc_seg: 100.0000  aux.loss_ce: 0.0098  aux.acc_seg: 100.0000\n",
            "12/15 21:23:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9901e-03  eta: 0:00:40  time: 0.2570  data_time: 0.0053  memory: 3340  loss: 0.0323  decode.loss_ce: 0.0204  decode.acc_seg: 99.3172  aux.loss_ce: 0.0119  aux.acc_seg: 99.3172\n",
            "12/15 21:23:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9890e-03  eta: 0:00:35  time: 0.2590  data_time: 0.0054  memory: 3340  loss: 0.0275  decode.loss_ce: 0.0172  decode.acc_seg: 99.6452  aux.loss_ce: 0.0102  aux.acc_seg: 99.6452\n",
            "12/15 21:23:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9879e-03  eta: 0:00:31  time: 0.2577  data_time: 0.0055  memory: 3340  loss: 0.0266  decode.loss_ce: 0.0168  decode.acc_seg: 99.7719  aux.loss_ce: 0.0098  aux.acc_seg: 99.7719\n",
            "12/15 21:23:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9867e-03  eta: 0:00:27  time: 0.2562  data_time: 0.0053  memory: 3340  loss: 0.0182  decode.loss_ce: 0.0110  decode.acc_seg: 99.5880  aux.loss_ce: 0.0072  aux.acc_seg: 99.5880\n",
            "12/15 21:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9856e-03  eta: 0:00:23  time: 0.2573  data_time: 0.0054  memory: 3340  loss: 0.0207  decode.loss_ce: 0.0129  decode.acc_seg: 99.8413  aux.loss_ce: 0.0078  aux.acc_seg: 99.8413\n",
            "12/15 21:23:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9845e-03  eta: 0:00:19  time: 0.2568  data_time: 0.0052  memory: 3340  loss: 0.0223  decode.loss_ce: 0.0141  decode.acc_seg: 99.1989  aux.loss_ce: 0.0082  aux.acc_seg: 99.1989\n",
            "12/15 21:23:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9834e-03  eta: 0:00:16  time: 0.2590  data_time: 0.0052  memory: 3340  loss: 0.0229  decode.loss_ce: 0.0147  decode.acc_seg: 99.4392  aux.loss_ce: 0.0082  aux.acc_seg: 99.4392\n",
            "12/15 21:23:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9823e-03  eta: 0:00:12  time: 0.2602  data_time: 0.0052  memory: 3340  loss: 0.0270  decode.loss_ce: 0.0177  decode.acc_seg: 98.7350  aux.loss_ce: 0.0093  aux.acc_seg: 98.7350\n",
            "12/15 21:23:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9812e-03  eta: 0:00:09  time: 0.2591  data_time: 0.0052  memory: 3340  loss: 0.0186  decode.loss_ce: 0.0117  decode.acc_seg: 99.8711  aux.loss_ce: 0.0068  aux.acc_seg: 99.8711\n",
            "12/15 21:23:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9801e-03  eta: 0:00:06  time: 0.2565  data_time: 0.0055  memory: 3340  loss: 0.0163  decode.loss_ce: 0.0102  decode.acc_seg: 99.4888  aux.loss_ce: 0.0061  aux.acc_seg: 99.4888\n",
            "12/15 21:24:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9789e-03  eta: 0:00:03  time: 0.2567  data_time: 0.0052  memory: 3340  loss: 0.0142  decode.loss_ce: 0.0088  decode.acc_seg: 99.8825  aux.loss_ce: 0.0054  aux.acc_seg: 99.8825\n",
            "12/15 21:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9778e-03  eta: 0:00:00  time: 0.2567  data_time: 0.0054  memory: 3340  loss: 0.0320  decode.loss_ce: 0.0215  decode.acc_seg: 100.0000  aux.loss_ce: 0.0105  aux.acc_seg: 100.0000\n",
            "12/15 21:24:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/15 21:24:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.2218  data_time: 0.0139  memory: 9266  \n",
            "12/15 21:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.0459  data_time: 0.0022  memory: 723  \n",
            "12/15 21:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/15 21:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.57 | 100.0 | 99.14 | 99.57  |   99.14   | 100.0  |\n",
            "| fluid |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/15 21:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.1400  mDice: 49.7800  mAcc: 50.0000  mIoU: 49.5700  mFscore: 99.5700  mPrecision: 99.1400  mRecall: 50.0000  data_time: 0.0076  time: 0.1260\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4xb4-80k_potsdam-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. FCN Pretrained on VOC Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config fcn_r50-d8_4xb4-20k_voc12aug-512x512 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:24:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_aug = dict(\n",
            "    ann_file='ImageSets/Segmentation/aug.txt',\n",
            "    data_prefix=dict(\n",
            "        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_train = dict(\n",
            "    ann_file='ImageSets/Segmentation/train.txt',\n",
            "    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=512,\n",
            "        concat_input=True,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=2,\n",
            "        type='FCNHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=20000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        datasets=[\n",
            "            dict(\n",
            "                ann_file='splits/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='image_png_256_gray',\n",
            "                    seg_map_path='fluid_png_256_binary'),\n",
            "                data_root=\n",
            "                '/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(keep_ratio=True, scale=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Resize'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='BOE_Chiu_Dataset'),\n",
            "            dict(\n",
            "                ann_file='splits/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='image_png_256_gray',\n",
            "                    seg_map_path='fluid_png_256_binary'),\n",
            "                data_root=\n",
            "                '/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(keep_ratio=True, scale=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Resize'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='BOE_Chiu_Dataset'),\n",
            "        ],\n",
            "        type='ConcatDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:24:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/15 21:24:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:24:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "12/15 21:24:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet50_v1c\n",
            "12/15 21:24:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n",
            "12/15 21:24:52 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([21, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 512, 1, 1]).\n",
            "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([21, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).\n",
            "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/15 21:24:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth\n",
            "12/15 21:24:52 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/15 21:24:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/15 21:24:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9960e-03  eta: 0:01:23  time: 0.4381  data_time: 0.0051  memory: 7928  loss: 0.3934  decode.loss_ce: 0.2332  decode.acc_seg: 98.0141  aux.loss_ce: 0.1602  aux.acc_seg: 98.0141\n",
            "12/15 21:24:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9915e-03  eta: 0:01:00  time: 0.2303  data_time: 0.0052  memory: 3069  loss: 0.0933  decode.loss_ce: 0.0651  decode.acc_seg: 97.4724  aux.loss_ce: 0.0282  aux.acc_seg: 97.4724\n",
            "12/15 21:25:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9871e-03  eta: 0:00:50  time: 0.2315  data_time: 0.0052  memory: 3069  loss: 0.0356  decode.loss_ce: 0.0242  decode.acc_seg: 99.7963  aux.loss_ce: 0.0113  aux.acc_seg: 99.7963\n",
            "12/15 21:25:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9826e-03  eta: 0:00:45  time: 0.2315  data_time: 0.0051  memory: 3069  loss: 0.0415  decode.loss_ce: 0.0266  decode.acc_seg: 99.5987  aux.loss_ce: 0.0149  aux.acc_seg: 99.5987\n",
            "12/15 21:25:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9782e-03  eta: 0:00:40  time: 0.2306  data_time: 0.0053  memory: 3069  loss: 0.0337  decode.loss_ce: 0.0191  decode.acc_seg: 99.4926  aux.loss_ce: 0.0146  aux.acc_seg: 99.4926\n",
            "12/15 21:25:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9737e-03  eta: 0:00:37  time: 0.2301  data_time: 0.0052  memory: 3069  loss: 0.0312  decode.loss_ce: 0.0178  decode.acc_seg: 98.5229  aux.loss_ce: 0.0135  aux.acc_seg: 98.5229\n",
            "12/15 21:25:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9693e-03  eta: 0:00:33  time: 0.2310  data_time: 0.0051  memory: 3069  loss: 0.0309  decode.loss_ce: 0.0179  decode.acc_seg: 99.4041  aux.loss_ce: 0.0130  aux.acc_seg: 99.4041\n",
            "12/15 21:25:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9648e-03  eta: 0:00:30  time: 0.2319  data_time: 0.0052  memory: 3069  loss: 0.0305  decode.loss_ce: 0.0173  decode.acc_seg: 99.9039  aux.loss_ce: 0.0132  aux.acc_seg: 99.9039\n",
            "12/15 21:25:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: fcn_r50-d8_4xb4-20k_voc12aug-512x512_20231215_212408\n",
            "12/15 21:25:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9603e-03  eta: 0:00:27  time: 0.2303  data_time: 0.0052  memory: 3069  loss: 0.0285  decode.loss_ce: 0.0168  decode.acc_seg: 99.4637  aux.loss_ce: 0.0116  aux.acc_seg: 99.4637\n",
            "12/15 21:25:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9559e-03  eta: 0:00:25  time: 0.2319  data_time: 0.0054  memory: 3069  loss: 0.0296  decode.loss_ce: 0.0173  decode.acc_seg: 99.9542  aux.loss_ce: 0.0123  aux.acc_seg: 99.9542\n",
            "12/15 21:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9514e-03  eta: 0:00:22  time: 0.2305  data_time: 0.0052  memory: 3069  loss: 0.0270  decode.loss_ce: 0.0161  decode.acc_seg: 98.6038  aux.loss_ce: 0.0110  aux.acc_seg: 98.6038\n",
            "12/15 21:25:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9470e-03  eta: 0:00:19  time: 0.2320  data_time: 0.0054  memory: 3069  loss: 0.0234  decode.loss_ce: 0.0140  decode.acc_seg: 99.8711  aux.loss_ce: 0.0094  aux.acc_seg: 99.8711\n",
            "12/15 21:25:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9425e-03  eta: 0:00:17  time: 0.2321  data_time: 0.0053  memory: 3069  loss: 0.0187  decode.loss_ce: 0.0115  decode.acc_seg: 98.9159  aux.loss_ce: 0.0072  aux.acc_seg: 98.9159\n",
            "12/15 21:25:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9381e-03  eta: 0:00:14  time: 0.2321  data_time: 0.0052  memory: 3069  loss: 0.0176  decode.loss_ce: 0.0108  decode.acc_seg: 99.7696  aux.loss_ce: 0.0068  aux.acc_seg: 99.7696\n",
            "12/15 21:25:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9336e-03  eta: 0:00:12  time: 0.2332  data_time: 0.0051  memory: 3069  loss: 0.0165  decode.loss_ce: 0.0101  decode.acc_seg: 99.8299  aux.loss_ce: 0.0064  aux.acc_seg: 99.8299\n",
            "12/15 21:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9291e-03  eta: 0:00:09  time: 0.2335  data_time: 0.0055  memory: 3069  loss: 0.0231  decode.loss_ce: 0.0146  decode.acc_seg: 99.3149  aux.loss_ce: 0.0085  aux.acc_seg: 99.3149\n",
            "12/15 21:25:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9247e-03  eta: 0:00:07  time: 0.2313  data_time: 0.0051  memory: 3069  loss: 0.0219  decode.loss_ce: 0.0138  decode.acc_seg: 99.5880  aux.loss_ce: 0.0081  aux.acc_seg: 99.5880\n",
            "12/15 21:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9202e-03  eta: 0:00:04  time: 0.2305  data_time: 0.0052  memory: 3069  loss: 0.0252  decode.loss_ce: 0.0164  decode.acc_seg: 99.7223  aux.loss_ce: 0.0088  aux.acc_seg: 99.7223\n",
            "12/15 21:25:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9158e-03  eta: 0:00:02  time: 0.2300  data_time: 0.0052  memory: 3069  loss: 0.0234  decode.loss_ce: 0.0150  decode.acc_seg: 98.2376  aux.loss_ce: 0.0084  aux.acc_seg: 98.2376\n",
            "12/15 21:25:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9113e-03  eta: 0:00:00  time: 0.2315  data_time: 0.0056  memory: 3069  loss: 0.0147  decode.loss_ce: 0.0092  decode.acc_seg: 99.3172  aux.loss_ce: 0.0055  aux.acc_seg: 99.3172\n",
            "12/15 21:25:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/15 21:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:01  time: 0.1192  data_time: 0.0141  memory: 5980  \n",
            "12/15 21:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.0453  data_time: 0.0023  memory: 639  \n",
            "12/15 21:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/15 21:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.57 | 100.0 | 99.14 | 99.57  |   99.14   | 100.0  |\n",
            "| fluid |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/15 21:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.1400  mDice: 49.7800  mAcc: 50.0000  mIoU: 49.5700  mFscore: 99.5700  mPrecision: 99.1400  mRecall: 50.0000  data_time: 0.0077  time: 0.0789\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_4xb4-20k_voc12aug-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False, dataset_num=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. DeepLabV3 Pretrained on VOC Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:25:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:26:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_aug = dict(\n",
            "    ann_file='ImageSets/Segmentation/aug.txt',\n",
            "    data_prefix=dict(\n",
            "        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_train = dict(\n",
            "    ann_file='ImageSets/Segmentation/train.txt',\n",
            "    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=512,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='ASPPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=20000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        datasets=[\n",
            "            dict(\n",
            "                ann_file='splits/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='image_png_256_gray',\n",
            "                    seg_map_path='fluid_png_256_binary'),\n",
            "                data_root=\n",
            "                '/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(keep_ratio=True, scale=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Resize'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='BOE_Chiu_Dataset'),\n",
            "            dict(\n",
            "                ann_file='splits/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='image_png_256_gray',\n",
            "                    seg_map_path='fluid_png_256_binary'),\n",
            "                data_root=\n",
            "                '/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(keep_ratio=True, scale=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Resize'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='BOE_Chiu_Dataset'),\n",
            "        ],\n",
            "        type='ConcatDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:26:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/15 21:26:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:26:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "12/15 21:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet50_v1c\n",
            "12/15 21:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n",
            "12/15 21:26:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([21, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 512, 1, 1]).\n",
            "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([21, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).\n",
            "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/15 21:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth\n",
            "12/15 21:26:38 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/15 21:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/15 21:26:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9960e-03  eta: 0:04:10  time: 1.3181  data_time: 0.0049  memory: 3271  loss: 0.3906  decode.loss_ce: 0.2288  decode.acc_seg: 98.0141  aux.loss_ce: 0.1618  aux.acc_seg: 98.0141\n",
            "12/15 21:26:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9915e-03  eta: 0:02:31  time: 0.3679  data_time: 0.0054  memory: 3271  loss: 0.1019  decode.loss_ce: 0.0734  decode.acc_seg: 97.4724  aux.loss_ce: 0.0285  aux.acc_seg: 97.4724\n",
            "12/15 21:26:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9871e-03  eta: 0:01:56  time: 0.3703  data_time: 0.0054  memory: 3271  loss: 0.0392  decode.loss_ce: 0.0277  decode.acc_seg: 99.7963  aux.loss_ce: 0.0115  aux.acc_seg: 99.7963\n",
            "12/15 21:27:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9826e-03  eta: 0:01:37  time: 0.3690  data_time: 0.0054  memory: 3271  loss: 0.0472  decode.loss_ce: 0.0311  decode.acc_seg: 99.5987  aux.loss_ce: 0.0160  aux.acc_seg: 99.5987\n",
            "12/15 21:27:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9782e-03  eta: 0:01:23  time: 0.3693  data_time: 0.0053  memory: 3271  loss: 0.0366  decode.loss_ce: 0.0220  decode.acc_seg: 99.4926  aux.loss_ce: 0.0146  aux.acc_seg: 99.4926\n",
            "12/15 21:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9737e-03  eta: 0:01:13  time: 0.3677  data_time: 0.0054  memory: 3271  loss: 0.0317  decode.loss_ce: 0.0178  decode.acc_seg: 98.5229  aux.loss_ce: 0.0139  aux.acc_seg: 98.5229\n",
            "12/15 21:27:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9693e-03  eta: 0:01:05  time: 0.3692  data_time: 0.0054  memory: 3271  loss: 0.0316  decode.loss_ce: 0.0182  decode.acc_seg: 99.4041  aux.loss_ce: 0.0135  aux.acc_seg: 99.4041\n",
            "12/15 21:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9648e-03  eta: 0:00:58  time: 0.3693  data_time: 0.0052  memory: 3271  loss: 0.0320  decode.loss_ce: 0.0183  decode.acc_seg: 99.9039  aux.loss_ce: 0.0137  aux.acc_seg: 99.9039\n",
            "12/15 21:27:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512_20231215_212554\n",
            "12/15 21:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9603e-03  eta: 0:00:52  time: 0.3687  data_time: 0.0054  memory: 3271  loss: 0.0314  decode.loss_ce: 0.0189  decode.acc_seg: 99.4637  aux.loss_ce: 0.0125  aux.acc_seg: 99.4637\n",
            "12/15 21:27:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9559e-03  eta: 0:00:46  time: 0.3695  data_time: 0.0052  memory: 3271  loss: 0.0316  decode.loss_ce: 0.0185  decode.acc_seg: 99.9542  aux.loss_ce: 0.0131  aux.acc_seg: 99.9542\n",
            "12/15 21:27:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9514e-03  eta: 0:00:40  time: 0.3701  data_time: 0.0052  memory: 3271  loss: 0.0306  decode.loss_ce: 0.0186  decode.acc_seg: 98.6038  aux.loss_ce: 0.0120  aux.acc_seg: 98.6038\n",
            "12/15 21:27:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9470e-03  eta: 0:00:35  time: 0.3689  data_time: 0.0051  memory: 3271  loss: 0.0263  decode.loss_ce: 0.0157  decode.acc_seg: 99.8711  aux.loss_ce: 0.0106  aux.acc_seg: 99.8711\n",
            "12/15 21:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9425e-03  eta: 0:00:30  time: 0.3680  data_time: 0.0054  memory: 3271  loss: 0.0203  decode.loss_ce: 0.0124  decode.acc_seg: 98.9159  aux.loss_ce: 0.0080  aux.acc_seg: 98.9159\n",
            "12/15 21:27:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9381e-03  eta: 0:00:26  time: 0.3701  data_time: 0.0053  memory: 3271  loss: 0.0185  decode.loss_ce: 0.0109  decode.acc_seg: 99.7696  aux.loss_ce: 0.0076  aux.acc_seg: 99.7696\n",
            "12/15 21:27:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9336e-03  eta: 0:00:21  time: 0.3692  data_time: 0.0052  memory: 3271  loss: 0.0178  decode.loss_ce: 0.0107  decode.acc_seg: 99.8299  aux.loss_ce: 0.0070  aux.acc_seg: 99.8299\n",
            "12/15 21:27:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9291e-03  eta: 0:00:17  time: 0.3693  data_time: 0.0053  memory: 3271  loss: 0.0244  decode.loss_ce: 0.0149  decode.acc_seg: 99.3149  aux.loss_ce: 0.0095  aux.acc_seg: 99.3149\n",
            "12/15 21:27:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9247e-03  eta: 0:00:12  time: 0.3680  data_time: 0.0053  memory: 3271  loss: 0.0236  decode.loss_ce: 0.0148  decode.acc_seg: 99.6021  aux.loss_ce: 0.0088  aux.acc_seg: 99.5880\n",
            "12/15 21:27:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9202e-03  eta: 0:00:08  time: 0.3702  data_time: 0.0052  memory: 3271  loss: 0.0262  decode.loss_ce: 0.0167  decode.acc_seg: 99.7223  aux.loss_ce: 0.0096  aux.acc_seg: 99.7223\n",
            "12/15 21:27:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9158e-03  eta: 0:00:04  time: 0.3690  data_time: 0.0052  memory: 3271  loss: 0.0246  decode.loss_ce: 0.0154  decode.acc_seg: 98.2838  aux.loss_ce: 0.0091  aux.acc_seg: 98.2376\n",
            "12/15 21:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9113e-03  eta: 0:00:00  time: 0.3691  data_time: 0.0051  memory: 3271  loss: 0.0151  decode.loss_ce: 0.0092  decode.acc_seg: 99.3172  aux.loss_ce: 0.0059  aux.acc_seg: 99.3172\n",
            "12/15 21:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/15 21:28:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:03  time: 0.2671  data_time: 0.0142  memory: 926  \n",
            "12/15 21:28:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.0677  data_time: 0.0021  memory: 772  \n",
            "12/15 21:28:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/15 21:28:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.66 | 99.97 | 99.33 | 99.66  |   99.36   | 99.97  |\n",
            "| fluid | 39.82 | 25.85 | 24.86 | 39.82  |   86.68   | 25.85  |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/15 21:28:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.3300  mDice: 69.7400  mAcc: 62.9100  mIoU: 62.0900  mFscore: 69.7400  mPrecision: 93.0200  mRecall: 62.9100  data_time: 0.0076  time: 0.1583\n"
          ]
        }
      ],
      "source": [
        "\n",
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False, dataset_num=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. DeepLabV3Plus Pretrained on Potsdam Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config deeplabv3plus_r18-d8_4xb4-80k_potsdam-512x512 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3plus_r18-d8_512x512_80k_potsdam_20211219_020601-75fd5bc3.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=256,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=18,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        c1_channels=12,\n",
            "        c1_in_channels=64,\n",
            "        channels=128,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=512,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='DepthwiseSeparableASPPHead'),\n",
            "    pretrained='open-mmlab://resnet18_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=80000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/15 21:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:30:15 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "12/15 21:30:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet18_v1c\n",
            "12/15 21:30:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet18_v1c\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.openmmlab.com/pretrain/third_party/resnet18_v1c-b5776b93.pth\" to /home/codespace/.cache/torch/hub/checkpoints/resnet18_v1c-b5776b93.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/15 21:30:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3plus_r18-d8_512x512_80k_potsdam_20211219_020601-75fd5bc3.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([6, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 128, 1, 1]).\n",
            "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([6, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 64, 1, 1]).\n",
            "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/15 21:30:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3plus_r18-d8_512x512_80k_potsdam_20211219_020601-75fd5bc3.pth\n",
            "12/15 21:30:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/15 21:30:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/15 21:30:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9990e-03  eta: 0:01:10  time: 0.3708  data_time: 0.0048  memory: 11154  loss: 0.5897  decode.loss_ce: 0.3831  decode.acc_seg: 98.5847  aux.loss_ce: 0.2066  aux.acc_seg: 98.5847\n",
            "12/15 21:30:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9979e-03  eta: 0:00:42  time: 0.0966  data_time: 0.0048  memory: 1047  loss: 0.1330  decode.loss_ce: 0.0627  decode.acc_seg: 99.4789  aux.loss_ce: 0.0703  aux.acc_seg: 99.4789\n",
            "12/15 21:30:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9968e-03  eta: 0:00:32  time: 0.0976  data_time: 0.0062  memory: 1047  loss: 0.0755  decode.loss_ce: 0.0444  decode.acc_seg: 99.9313  aux.loss_ce: 0.0311  aux.acc_seg: 99.9313\n",
            "12/15 21:30:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9957e-03  eta: 0:00:26  time: 0.0984  data_time: 0.0050  memory: 1047  loss: 0.0426  decode.loss_ce: 0.0234  decode.acc_seg: 98.6740  aux.loss_ce: 0.0192  aux.acc_seg: 98.6740\n",
            "12/15 21:30:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: deeplabv3plus_r18-d8_4xb4-80k_potsdam-512x512_20231215_212933\n",
            "12/15 21:30:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9945e-03  eta: 0:00:22  time: 0.0978  data_time: 0.0054  memory: 1047  loss: 0.0326  decode.loss_ce: 0.0183  decode.acc_seg: 98.1880  aux.loss_ce: 0.0143  aux.acc_seg: 98.1880\n",
            "12/15 21:30:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9934e-03  eta: 0:00:20  time: 0.0962  data_time: 0.0048  memory: 1047  loss: 0.0405  decode.loss_ce: 0.0237  decode.acc_seg: 99.3599  aux.loss_ce: 0.0168  aux.acc_seg: 99.3599\n",
            "12/15 21:30:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9923e-03  eta: 0:00:17  time: 0.0956  data_time: 0.0048  memory: 1047  loss: 0.0300  decode.loss_ce: 0.0178  decode.acc_seg: 99.9016  aux.loss_ce: 0.0122  aux.acc_seg: 99.9016\n",
            "12/15 21:30:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9912e-03  eta: 0:00:15  time: 0.0955  data_time: 0.0049  memory: 1047  loss: 0.0263  decode.loss_ce: 0.0150  decode.acc_seg: 100.0000  aux.loss_ce: 0.0112  aux.acc_seg: 100.0000\n",
            "12/15 21:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9901e-03  eta: 0:00:13  time: 0.0960  data_time: 0.0047  memory: 1047  loss: 0.0352  decode.loss_ce: 0.0220  decode.acc_seg: 99.3172  aux.loss_ce: 0.0132  aux.acc_seg: 99.3172\n",
            "12/15 21:30:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9890e-03  eta: 0:00:12  time: 0.0957  data_time: 0.0049  memory: 1047  loss: 0.0306  decode.loss_ce: 0.0194  decode.acc_seg: 99.6452  aux.loss_ce: 0.0113  aux.acc_seg: 99.6452\n",
            "12/15 21:30:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9879e-03  eta: 0:00:10  time: 0.0968  data_time: 0.0049  memory: 1047  loss: 0.0292  decode.loss_ce: 0.0184  decode.acc_seg: 99.7719  aux.loss_ce: 0.0109  aux.acc_seg: 99.7719\n",
            "12/15 21:30:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9867e-03  eta: 0:00:09  time: 0.0958  data_time: 0.0047  memory: 1047  loss: 0.0198  decode.loss_ce: 0.0121  decode.acc_seg: 99.5880  aux.loss_ce: 0.0077  aux.acc_seg: 99.5880\n",
            "12/15 21:30:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9856e-03  eta: 0:00:08  time: 0.0972  data_time: 0.0050  memory: 1047  loss: 0.0218  decode.loss_ce: 0.0137  decode.acc_seg: 99.8413  aux.loss_ce: 0.0080  aux.acc_seg: 99.8413\n",
            "12/15 21:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9845e-03  eta: 0:00:06  time: 0.0963  data_time: 0.0049  memory: 1047  loss: 0.0243  decode.loss_ce: 0.0156  decode.acc_seg: 99.1989  aux.loss_ce: 0.0087  aux.acc_seg: 99.1989\n",
            "12/15 21:30:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9834e-03  eta: 0:00:05  time: 0.0958  data_time: 0.0048  memory: 1047  loss: 0.0241  decode.loss_ce: 0.0154  decode.acc_seg: 99.4392  aux.loss_ce: 0.0087  aux.acc_seg: 99.4392\n",
            "12/15 21:30:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9823e-03  eta: 0:00:04  time: 0.0956  data_time: 0.0048  memory: 1047  loss: 0.0281  decode.loss_ce: 0.0186  decode.acc_seg: 98.7350  aux.loss_ce: 0.0095  aux.acc_seg: 98.7350\n",
            "12/15 21:30:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9812e-03  eta: 0:00:03  time: 0.0955  data_time: 0.0047  memory: 1047  loss: 0.0202  decode.loss_ce: 0.0130  decode.acc_seg: 99.8711  aux.loss_ce: 0.0072  aux.acc_seg: 99.8711\n",
            "12/15 21:30:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9801e-03  eta: 0:00:02  time: 0.0952  data_time: 0.0046  memory: 1047  loss: 0.0172  decode.loss_ce: 0.0110  decode.acc_seg: 99.4888  aux.loss_ce: 0.0063  aux.acc_seg: 99.4888\n",
            "12/15 21:30:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9789e-03  eta: 0:00:01  time: 0.0958  data_time: 0.0048  memory: 1047  loss: 0.0149  decode.loss_ce: 0.0091  decode.acc_seg: 99.8825  aux.loss_ce: 0.0058  aux.acc_seg: 99.8825\n",
            "12/15 21:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9778e-03  eta: 0:00:00  time: 0.0976  data_time: 0.0055  memory: 1047  loss: 0.0328  decode.loss_ce: 0.0220  decode.acc_seg: 100.0000  aux.loss_ce: 0.0108  aux.acc_seg: 100.0000\n",
            "12/15 21:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/15 21:30:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:00  time: 0.0516  data_time: 0.0142  memory: 4362  \n",
            "12/15 21:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.0215  data_time: 0.0021  memory: 262  \n",
            "12/15 21:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/15 21:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.57 | 100.0 | 99.14 | 99.57  |   99.14   | 100.0  |\n",
            "| fluid |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/15 21:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.1400  mDice: 49.7800  mAcc: 50.0000  mIoU: 49.5700  mFscore: 99.5700  mPrecision: 99.1400  mRecall: 50.0000  data_time: 0.0076  time: 0.0351\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3plus_r18-d8_4xb4-80k_potsdam-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3plus_r18-d8_512x512_80k_potsdam_20211219_020601-75fd5bc3.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False, dataset_num=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
