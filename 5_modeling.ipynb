{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "from pretrained_model import *\n",
        "from mmseg.registry import DATASETS\n",
        "from mmseg.datasets import *\n",
        "%cd mmsegmentation\n",
        "\n",
        "root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
        "img_dir = 'image_png_256_gray'\n",
        "ann_dir = 'fluid_png_256_binary'\n",
        "\n",
        "classes = ('image', 'fluid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "@DATASETS.register_module()\n",
        "class BOE_Chiu_Dataset(BaseSegDataset):\n",
        "    METAINFO = dict(classes = classes)\n",
        "    def __init__(self,dataset=None, times=None, **kwargs):\n",
        "        super(BOE_Chiu_Dataset, self).__init__(img_suffix='.png', seg_map_suffix='.png', **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. UNET with FCN Head Pretrained on HRF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_fcn_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/14 19:34:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:34:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 19:34:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:34:03 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth\n",
            "12/14 19:34:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth\n",
            "12/14 19:34:03 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 19:34:03 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "12/14 19:34:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 19:34:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:02:06  time: 0.6632  data_time: 0.0040  memory: 10544  loss: 0.0798  decode.loss_ce: 0.0571  decode.acc_seg: 99.2973  aux.loss_ce: 0.0227  aux.acc_seg: 99.2973\n",
            "12/14 19:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:16  time: 0.1839  data_time: 0.0044  memory: 4702  loss: 0.0402  decode.loss_ce: 0.0276  decode.acc_seg: 99.8108  aux.loss_ce: 0.0127  aux.acc_seg: 99.8108\n",
            "12/14 19:34:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:00:58  time: 0.1856  data_time: 0.0043  memory: 4702  loss: 0.0426  decode.loss_ce: 0.0299  decode.acc_seg: 99.9931  aux.loss_ce: 0.0126  aux.acc_seg: 99.9931\n",
            "12/14 19:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:00:48  time: 0.1855  data_time: 0.0046  memory: 4702  loss: 0.0296  decode.loss_ce: 0.0203  decode.acc_seg: 99.3652  aux.loss_ce: 0.0093  aux.acc_seg: 99.3652\n",
            "12/14 19:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_fcn_4xb4-40k_hrf-256x256_20231214_193400\n",
            "12/14 19:34:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:00:42  time: 0.1839  data_time: 0.0044  memory: 4702  loss: 0.0242  decode.loss_ce: 0.0160  decode.acc_seg: 98.8808  aux.loss_ce: 0.0082  aux.acc_seg: 98.8808\n",
            "12/14 19:34:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:00:37  time: 0.1851  data_time: 0.0044  memory: 4702  loss: 0.0328  decode.loss_ce: 0.0229  decode.acc_seg: 99.7147  aux.loss_ce: 0.0099  aux.acc_seg: 99.7147\n",
            "12/14 19:34:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:00:32  time: 0.1838  data_time: 0.0044  memory: 4702  loss: 0.0220  decode.loss_ce: 0.0149  decode.acc_seg: 99.9893  aux.loss_ce: 0.0071  aux.acc_seg: 99.9893\n",
            "12/14 19:34:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:29  time: 0.1838  data_time: 0.0046  memory: 4702  loss: 0.0219  decode.loss_ce: 0.0150  decode.acc_seg: 100.0000  aux.loss_ce: 0.0069  aux.acc_seg: 100.0000\n",
            "12/14 19:34:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:26  time: 0.1831  data_time: 0.0043  memory: 4702  loss: 0.0240  decode.loss_ce: 0.0165  decode.acc_seg: 99.7917  aux.loss_ce: 0.0074  aux.acc_seg: 99.7917\n",
            "12/14 19:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:23  time: 0.1838  data_time: 0.0042  memory: 4702  loss: 0.0205  decode.loss_ce: 0.0139  decode.acc_seg: 99.8444  aux.loss_ce: 0.0066  aux.acc_seg: 99.8716\n",
            "12/14 19:34:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:20  time: 0.1855  data_time: 0.0049  memory: 4702  loss: 0.0189  decode.loss_ce: 0.0126  decode.acc_seg: 99.9031  aux.loss_ce: 0.0063  aux.acc_seg: 99.8873\n",
            "12/14 19:34:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:17  time: 0.1864  data_time: 0.0052  memory: 4702  loss: 0.0138  decode.loss_ce: 0.0088  decode.acc_seg: 99.7910  aux.loss_ce: 0.0050  aux.acc_seg: 99.7910\n",
            "12/14 19:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:15  time: 0.1837  data_time: 0.0043  memory: 4702  loss: 0.0160  decode.loss_ce: 0.0106  decode.acc_seg: 99.9405  aux.loss_ce: 0.0055  aux.acc_seg: 99.9475\n",
            "12/14 19:34:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:13  time: 0.1845  data_time: 0.0043  memory: 4702  loss: 0.0156  decode.loss_ce: 0.0102  decode.acc_seg: 99.5186  aux.loss_ce: 0.0054  aux.acc_seg: 99.5186\n",
            "12/14 19:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:10  time: 0.1840  data_time: 0.0043  memory: 4702  loss: 0.0168  decode.loss_ce: 0.0112  decode.acc_seg: 99.7955  aux.loss_ce: 0.0056  aux.acc_seg: 99.7545\n",
            "12/14 19:34:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:08  time: 0.1870  data_time: 0.0060  memory: 4702  loss: 0.0181  decode.loss_ce: 0.0120  decode.acc_seg: 99.3774  aux.loss_ce: 0.0060  aux.acc_seg: 99.4020\n",
            "12/14 19:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:06  time: 0.1831  data_time: 0.0044  memory: 4702  loss: 0.0135  decode.loss_ce: 0.0089  decode.acc_seg: 99.9466  aux.loss_ce: 0.0045  aux.acc_seg: 99.9460\n",
            "12/14 19:34:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:04  time: 0.1838  data_time: 0.0043  memory: 4702  loss: 0.0102  decode.loss_ce: 0.0068  decode.acc_seg: 99.7597  aux.loss_ce: 0.0035  aux.acc_seg: 99.7593\n",
            "12/14 19:34:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:02  time: 0.1836  data_time: 0.0043  memory: 4702  loss: 0.0102  decode.loss_ce: 0.0065  decode.acc_seg: 99.9550  aux.loss_ce: 0.0037  aux.acc_seg: 99.9483\n",
            "12/14 19:34:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.1832  data_time: 0.0043  memory: 4702  loss: 0.0210  decode.loss_ce: 0.0144  decode.acc_seg: 100.0000  aux.loss_ce: 0.0066  aux.acc_seg: 100.0000\n",
            "12/14 19:34:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 19:34:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:03  time: 0.3132  data_time: 0.0140  memory: 9010  \n",
            "12/14 19:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1210  data_time: 0.0022  memory: 372  \n",
            "12/14 19:34:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 19:34:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.73 | 100.0 | 99.47 | 99.73  |   99.47   | 100.0  |\n",
            "| fluid |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 19:34:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 49.8700  mAcc: 50.0000  mIoU: 49.7300  mFscore: 99.7300  mPrecision: 99.4700  mRecall: 50.0000  data_time: 0.0076  time: 0.2086\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_fcn_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. UNET with PSPNet Head Pretrained on HRF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing unet-s5-d16_pspnet_4xb4-40k_hrf-256x256...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.9/110.9 MiB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped unet-s5-d16_pspnet_4xb4-40k_hrf-256x256.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_pspnet_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:32:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:32:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=16,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        pool_scales=(\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "            6,\n",
            "        ),\n",
            "        type='PSPHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:32:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 03:32:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:32:47 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth\n",
            "12/14 03:32:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth\n",
            "12/14 03:32:48 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 03:32:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 03:32:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:01:38  time: 0.5177  data_time: 0.0044  memory: 9486  loss: 0.0809  decode.loss_ce: 0.0572  decode.acc_seg: 99.2973  aux.loss_ce: 0.0236  aux.acc_seg: 99.2973\n",
            "12/14 03:32:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:28  time: 0.4640  data_time: 0.0047  memory: 4607  loss: 0.0442  decode.loss_ce: 0.0299  decode.acc_seg: 99.8108  aux.loss_ce: 0.0143  aux.acc_seg: 99.8108\n",
            "12/14 03:33:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:01:21  time: 0.4638  data_time: 0.0050  memory: 4607  loss: 0.0431  decode.loss_ce: 0.0294  decode.acc_seg: 99.9931  aux.loss_ce: 0.0138  aux.acc_seg: 99.9931\n",
            "12/14 03:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:01:16  time: 0.4646  data_time: 0.0047  memory: 4607  loss: 0.0337  decode.loss_ce: 0.0238  decode.acc_seg: 99.3652  aux.loss_ce: 0.0099  aux.acc_seg: 99.3652\n",
            "12/14 03:33:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_pspnet_4xb4-40k_hrf-256x256_20231214_033205\n",
            "12/14 03:33:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:01:11  time: 0.4652  data_time: 0.0050  memory: 4607  loss: 0.0251  decode.loss_ce: 0.0175  decode.acc_seg: 98.8808  aux.loss_ce: 0.0076  aux.acc_seg: 98.8808\n",
            "12/14 03:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:01:06  time: 0.4650  data_time: 0.0052  memory: 4607  loss: 0.0339  decode.loss_ce: 0.0239  decode.acc_seg: 99.7168  aux.loss_ce: 0.0100  aux.acc_seg: 99.7147\n",
            "12/14 03:33:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:01:01  time: 0.4633  data_time: 0.0048  memory: 4607  loss: 0.0213  decode.loss_ce: 0.0143  decode.acc_seg: 99.9893  aux.loss_ce: 0.0070  aux.acc_seg: 99.9893\n",
            "12/14 03:33:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:56  time: 0.4634  data_time: 0.0047  memory: 4607  loss: 0.0242  decode.loss_ce: 0.0159  decode.acc_seg: 100.0000  aux.loss_ce: 0.0082  aux.acc_seg: 100.0000\n",
            "12/14 03:33:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:51  time: 0.4633  data_time: 0.0051  memory: 4607  loss: 0.0238  decode.loss_ce: 0.0160  decode.acc_seg: 99.7917  aux.loss_ce: 0.0078  aux.acc_seg: 99.7917\n",
            "12/14 03:33:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:46  time: 0.4649  data_time: 0.0047  memory: 4607  loss: 0.0201  decode.loss_ce: 0.0134  decode.acc_seg: 99.7433  aux.loss_ce: 0.0066  aux.acc_seg: 99.8444\n",
            "12/14 03:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:42  time: 0.4629  data_time: 0.0048  memory: 4607  loss: 0.0187  decode.loss_ce: 0.0119  decode.acc_seg: 99.9018  aux.loss_ce: 0.0067  aux.acc_seg: 99.9031\n",
            "12/14 03:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:37  time: 0.4655  data_time: 0.0054  memory: 4607  loss: 0.0130  decode.loss_ce: 0.0082  decode.acc_seg: 99.8686  aux.loss_ce: 0.0048  aux.acc_seg: 99.7910\n",
            "12/14 03:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:32  time: 0.4629  data_time: 0.0046  memory: 4607  loss: 0.0147  decode.loss_ce: 0.0094  decode.acc_seg: 99.9483  aux.loss_ce: 0.0053  aux.acc_seg: 99.9405\n",
            "12/14 03:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:28  time: 0.4623  data_time: 0.0048  memory: 4607  loss: 0.0157  decode.loss_ce: 0.0102  decode.acc_seg: 99.6620  aux.loss_ce: 0.0055  aux.acc_seg: 99.5186\n",
            "12/14 03:33:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:23  time: 0.4635  data_time: 0.0047  memory: 4607  loss: 0.0151  decode.loss_ce: 0.0095  decode.acc_seg: 99.8138  aux.loss_ce: 0.0056  aux.acc_seg: 99.7992\n",
            "12/14 03:34:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:18  time: 0.4641  data_time: 0.0047  memory: 4607  loss: 0.0180  decode.loss_ce: 0.0120  decode.acc_seg: 99.5224  aux.loss_ce: 0.0060  aux.acc_seg: 99.3774\n",
            "12/14 03:34:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:14  time: 0.4634  data_time: 0.0047  memory: 4607  loss: 0.0122  decode.loss_ce: 0.0076  decode.acc_seg: 99.9512  aux.loss_ce: 0.0046  aux.acc_seg: 99.9466\n",
            "12/14 03:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:09  time: 0.4647  data_time: 0.0046  memory: 4607  loss: 0.0091  decode.loss_ce: 0.0054  decode.acc_seg: 99.7644  aux.loss_ce: 0.0037  aux.acc_seg: 99.7597\n",
            "12/14 03:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:04  time: 0.4620  data_time: 0.0047  memory: 4607  loss: 0.0093  decode.loss_ce: 0.0058  decode.acc_seg: 99.9554  aux.loss_ce: 0.0035  aux.acc_seg: 99.9598\n",
            "12/14 03:34:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.4620  data_time: 0.0049  memory: 4607  loss: 0.0184  decode.loss_ce: 0.0117  decode.acc_seg: 100.0000  aux.loss_ce: 0.0066  aux.acc_seg: 100.0000\n",
            "12/14 03:34:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 03:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.1903  data_time: 0.0132  memory: 1592  \n",
            "12/14 03:34:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1505  data_time: 0.0026  memory: 372  \n",
            "12/14 03:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 03:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.73 | 99.98 | 99.47 | 99.73  |   99.49   | 99.98  |\n",
            "| fluid |  7.47 |  4.04 |  3.88 |  7.47  |   49.76   |  4.04  |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 03:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 53.6000  mAcc: 52.0100  mIoU: 51.6700  mFscore: 53.6000  mPrecision: 74.6200  mRecall: 52.0100  data_time: 0.0075  time: 0.1687\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_pspnet_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. UNET with DeepLabV3 Pretrained on HRF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 MiB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/14 03:35:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=16,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='ASPPHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 03:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:35:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth\n",
            "12/14 03:35:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth\n",
            "12/14 03:35:09 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 03:35:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 03:35:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:01:25  time: 0.4497  data_time: 0.0045  memory: 7822  loss: 0.0893  decode.loss_ce: 0.0629  decode.acc_seg: 99.2973  aux.loss_ce: 0.0264  aux.acc_seg: 99.2973\n",
            "12/14 03:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:07  time: 0.3015  data_time: 0.0050  memory: 4642  loss: 0.0433  decode.loss_ce: 0.0295  decode.acc_seg: 99.8108  aux.loss_ce: 0.0137  aux.acc_seg: 99.8108\n",
            "12/14 03:35:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:00:59  time: 0.2982  data_time: 0.0048  memory: 4642  loss: 0.0456  decode.loss_ce: 0.0313  decode.acc_seg: 99.9931  aux.loss_ce: 0.0144  aux.acc_seg: 99.9931\n",
            "12/14 03:35:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:00:53  time: 0.2990  data_time: 0.0047  memory: 4642  loss: 0.0337  decode.loss_ce: 0.0234  decode.acc_seg: 99.3652  aux.loss_ce: 0.0103  aux.acc_seg: 99.3652\n",
            "12/14 03:35:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256_20231214_033426\n",
            "12/14 03:35:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:00:49  time: 0.3021  data_time: 0.0053  memory: 4642  loss: 0.0288  decode.loss_ce: 0.0206  decode.acc_seg: 98.8808  aux.loss_ce: 0.0082  aux.acc_seg: 98.8808\n",
            "12/14 03:35:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:00:45  time: 0.2993  data_time: 0.0048  memory: 4642  loss: 0.0374  decode.loss_ce: 0.0259  decode.acc_seg: 99.7108  aux.loss_ce: 0.0114  aux.acc_seg: 99.7147\n",
            "12/14 03:35:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:00:41  time: 0.3009  data_time: 0.0046  memory: 4642  loss: 0.0217  decode.loss_ce: 0.0140  decode.acc_seg: 99.9893  aux.loss_ce: 0.0077  aux.acc_seg: 99.9893\n",
            "12/14 03:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:38  time: 0.2986  data_time: 0.0047  memory: 4642  loss: 0.0248  decode.loss_ce: 0.0165  decode.acc_seg: 100.0000  aux.loss_ce: 0.0084  aux.acc_seg: 100.0000\n",
            "12/14 03:35:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:34  time: 0.2999  data_time: 0.0046  memory: 4642  loss: 0.0257  decode.loss_ce: 0.0173  decode.acc_seg: 99.4957  aux.loss_ce: 0.0084  aux.acc_seg: 99.7917\n",
            "12/14 03:35:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:31  time: 0.2997  data_time: 0.0048  memory: 4642  loss: 0.0242  decode.loss_ce: 0.0168  decode.acc_seg: 99.8442  aux.loss_ce: 0.0074  aux.acc_seg: 99.8480\n",
            "12/14 03:35:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:28  time: 0.2999  data_time: 0.0048  memory: 4642  loss: 0.0184  decode.loss_ce: 0.0119  decode.acc_seg: 99.8764  aux.loss_ce: 0.0065  aux.acc_seg: 99.8816\n",
            "12/14 03:35:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:24  time: 0.2982  data_time: 0.0045  memory: 4642  loss: 0.0133  decode.loss_ce: 0.0083  decode.acc_seg: 99.8600  aux.loss_ce: 0.0049  aux.acc_seg: 99.7913\n",
            "12/14 03:35:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:21  time: 0.2987  data_time: 0.0047  memory: 4642  loss: 0.0156  decode.loss_ce: 0.0097  decode.acc_seg: 99.8663  aux.loss_ce: 0.0058  aux.acc_seg: 99.9369\n",
            "12/14 03:35:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:18  time: 0.2998  data_time: 0.0047  memory: 4642  loss: 0.0167  decode.loss_ce: 0.0110  decode.acc_seg: 99.6031  aux.loss_ce: 0.0057  aux.acc_seg: 99.5436\n",
            "12/14 03:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:15  time: 0.2985  data_time: 0.0047  memory: 4642  loss: 0.0163  decode.loss_ce: 0.0104  decode.acc_seg: 99.7448  aux.loss_ce: 0.0059  aux.acc_seg: 99.7406\n",
            "12/14 03:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:12  time: 0.2985  data_time: 0.0047  memory: 4642  loss: 0.0184  decode.loss_ce: 0.0126  decode.acc_seg: 99.5214  aux.loss_ce: 0.0059  aux.acc_seg: 99.4762\n",
            "12/14 03:36:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:09  time: 0.2976  data_time: 0.0048  memory: 4642  loss: 0.0128  decode.loss_ce: 0.0082  decode.acc_seg: 99.9498  aux.loss_ce: 0.0046  aux.acc_seg: 99.9466\n",
            "12/14 03:36:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:06  time: 0.3011  data_time: 0.0050  memory: 4642  loss: 0.0094  decode.loss_ce: 0.0057  decode.acc_seg: 99.7507  aux.loss_ce: 0.0037  aux.acc_seg: 99.7599\n",
            "12/14 03:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:03  time: 0.2988  data_time: 0.0047  memory: 4642  loss: 0.0097  decode.loss_ce: 0.0060  decode.acc_seg: 99.9435  aux.loss_ce: 0.0037  aux.acc_seg: 99.9548\n",
            "12/14 03:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.2979  data_time: 0.0048  memory: 4642  loss: 0.0181  decode.loss_ce: 0.0118  decode.acc_seg: 100.0000  aux.loss_ce: 0.0063  aux.acc_seg: 100.0000\n",
            "12/14 03:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 03:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.1785  data_time: 0.0138  memory: 1151  \n",
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1488  data_time: 0.0023  memory: 373  \n",
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.75 | 99.98 | 99.51 | 99.75  |   99.52   | 99.98  |\n",
            "| fluid | 19.18 | 10.94 | 10.61 | 19.18  |   77.55   | 10.94  |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.5100  mDice: 59.4600  mAcc: 55.4600  mIoU: 55.0600  mFscore: 59.4600  mPrecision: 88.5400  mRecall: 55.4600  data_time: 0.0076  time: 0.1621\n"
          ]
        }
      ],
      "source": [
        "\n",
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. PSPNET Pretrained on Postdam Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing pspnet_r50-d8_4xb4-80k_potsdam-512x512...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.1/187.1 MiB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped pspnet_r50-d8_4xb4-80k_potsdam-512x512.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !mim download mmsegmentation --config pspnet_r50-d8_4xb4-80k_potsdam-512x512 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=512,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        pool_scales=(\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "            6,\n",
            "        ),\n",
            "        type='PSPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=80000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 03:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:36:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "12/14 03:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet50_v1c\n",
            "12/14 03:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n",
            "12/14 03:36:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([6, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 512, 1, 1]).\n",
            "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([6, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).\n",
            "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/14 03:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth\n",
            "12/14 03:36:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 03:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 03:37:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9990e-03  eta: 0:03:31  time: 1.1154  data_time: 0.0047  memory: 11247  loss: 0.6101  decode.loss_ce: 0.3875  decode.acc_seg: 99.2973  aux.loss_ce: 0.2226  aux.acc_seg: 99.2973\n",
            "12/14 03:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9979e-03  eta: 0:02:03  time: 0.2565  data_time: 0.0051  memory: 3343  loss: 0.1122  decode.loss_ce: 0.0418  decode.acc_seg: 99.8108  aux.loss_ce: 0.0704  aux.acc_seg: 99.8108\n",
            "12/14 03:37:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9968e-03  eta: 0:01:32  time: 0.2569  data_time: 0.0048  memory: 3343  loss: 0.0510  decode.loss_ce: 0.0244  decode.acc_seg: 99.9931  aux.loss_ce: 0.0267  aux.acc_seg: 99.9931\n",
            "12/14 03:37:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9957e-03  eta: 0:01:15  time: 0.2564  data_time: 0.0050  memory: 3343  loss: 0.0282  decode.loss_ce: 0.0130  decode.acc_seg: 99.3652  aux.loss_ce: 0.0152  aux.acc_seg: 99.3652\n",
            "12/14 03:37:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: pspnet_r50-d8_4xb4-80k_potsdam-512x512_20231214_033615\n",
            "12/14 03:37:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9945e-03  eta: 0:01:04  time: 0.2565  data_time: 0.0051  memory: 3343  loss: 0.0214  decode.loss_ce: 0.0105  decode.acc_seg: 98.8808  aux.loss_ce: 0.0109  aux.acc_seg: 98.8808\n",
            "12/14 03:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9934e-03  eta: 0:00:55  time: 0.2568  data_time: 0.0049  memory: 3343  loss: 0.0284  decode.loss_ce: 0.0159  decode.acc_seg: 99.7147  aux.loss_ce: 0.0125  aux.acc_seg: 99.7147\n",
            "12/14 03:37:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9923e-03  eta: 0:00:49  time: 0.2590  data_time: 0.0051  memory: 3343  loss: 0.0193  decode.loss_ce: 0.0103  decode.acc_seg: 99.9893  aux.loss_ce: 0.0090  aux.acc_seg: 99.9893\n",
            "12/14 03:37:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9912e-03  eta: 0:00:43  time: 0.2592  data_time: 0.0049  memory: 3343  loss: 0.0186  decode.loss_ce: 0.0097  decode.acc_seg: 100.0000  aux.loss_ce: 0.0088  aux.acc_seg: 100.0000\n",
            "12/14 03:37:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9901e-03  eta: 0:00:38  time: 0.2560  data_time: 0.0052  memory: 3343  loss: 0.0233  decode.loss_ce: 0.0137  decode.acc_seg: 99.7917  aux.loss_ce: 0.0096  aux.acc_seg: 99.7917\n",
            "12/14 03:37:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9890e-03  eta: 0:00:34  time: 0.2583  data_time: 0.0051  memory: 3343  loss: 0.0200  decode.loss_ce: 0.0118  decode.acc_seg: 99.8444  aux.loss_ce: 0.0082  aux.acc_seg: 99.8444\n",
            "12/14 03:37:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9879e-03  eta: 0:00:30  time: 0.2554  data_time: 0.0049  memory: 3343  loss: 0.0196  decode.loss_ce: 0.0117  decode.acc_seg: 99.9031  aux.loss_ce: 0.0078  aux.acc_seg: 99.9031\n",
            "12/14 03:37:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9867e-03  eta: 0:00:26  time: 0.2577  data_time: 0.0052  memory: 3343  loss: 0.0128  decode.loss_ce: 0.0069  decode.acc_seg: 99.7910  aux.loss_ce: 0.0058  aux.acc_seg: 99.7910\n",
            "12/14 03:37:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9856e-03  eta: 0:00:22  time: 0.2552  data_time: 0.0049  memory: 3343  loss: 0.0153  decode.loss_ce: 0.0089  decode.acc_seg: 99.9405  aux.loss_ce: 0.0064  aux.acc_seg: 99.9405\n",
            "12/14 03:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9845e-03  eta: 0:00:19  time: 0.2586  data_time: 0.0049  memory: 3343  loss: 0.0155  decode.loss_ce: 0.0092  decode.acc_seg: 99.5186  aux.loss_ce: 0.0063  aux.acc_seg: 99.5186\n",
            "12/14 03:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9834e-03  eta: 0:00:15  time: 0.2574  data_time: 0.0051  memory: 3343  loss: 0.0159  decode.loss_ce: 0.0096  decode.acc_seg: 99.7955  aux.loss_ce: 0.0063  aux.acc_seg: 99.7955\n",
            "12/14 03:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9823e-03  eta: 0:00:12  time: 0.2580  data_time: 0.0049  memory: 3343  loss: 0.0188  decode.loss_ce: 0.0117  decode.acc_seg: 99.3774  aux.loss_ce: 0.0071  aux.acc_seg: 99.3774\n",
            "12/14 03:37:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9812e-03  eta: 0:00:09  time: 0.2549  data_time: 0.0049  memory: 3343  loss: 0.0132  decode.loss_ce: 0.0079  decode.acc_seg: 99.9466  aux.loss_ce: 0.0052  aux.acc_seg: 99.9466\n",
            "12/14 03:37:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9801e-03  eta: 0:00:06  time: 0.2574  data_time: 0.0048  memory: 3343  loss: 0.0097  decode.loss_ce: 0.0054  decode.acc_seg: 99.7597  aux.loss_ce: 0.0042  aux.acc_seg: 99.7597\n",
            "12/14 03:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9789e-03  eta: 0:00:03  time: 0.2567  data_time: 0.0049  memory: 3343  loss: 0.0098  decode.loss_ce: 0.0056  decode.acc_seg: 99.9550  aux.loss_ce: 0.0042  aux.acc_seg: 99.9550\n",
            "12/14 03:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9778e-03  eta: 0:00:00  time: 0.2555  data_time: 0.0048  memory: 3343  loss: 0.0217  decode.loss_ce: 0.0142  decode.acc_seg: 100.0000  aux.loss_ce: 0.0075  aux.acc_seg: 100.0000\n",
            "12/14 03:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.2216  data_time: 0.0144  memory: 9266  \n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.0466  data_time: 0.0023  memory: 724  \n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.73 | 100.0 | 99.47 | 99.73  |   99.47   | 100.0  |\n",
            "| fluid |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 49.8700  mAcc: 50.0000  mIoU: 49.7300  mFscore: 99.7300  mPrecision: 99.4700  mRecall: 50.0000  data_time: 0.0078  time: 0.1263\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4xb4-80k_potsdam-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. DeepLabV3 Pretrained on VOC Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512...\n",
            "\u001b[32mdeeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth exists in /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !mim download mmsegmentation --config deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:36:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_aug = dict(\n",
            "    ann_file='ImageSets/Segmentation/aug.txt',\n",
            "    data_prefix=dict(\n",
            "        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_train = dict(\n",
            "    ann_file='ImageSets/Segmentation/train.txt',\n",
            "    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=512,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='ASPPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=20000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        datasets=[\n",
            "            dict(\n",
            "                ann_file='splits/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='image_png_256_gray',\n",
            "                    seg_map_path='fluid_png_256_binary'),\n",
            "                data_root=\n",
            "                '/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(keep_ratio=True, scale=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Resize'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='BOE_Chiu_Dataset'),\n",
            "            dict(\n",
            "                ann_file='splits/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='image_png_256_gray',\n",
            "                    seg_map_path='fluid_png_256_binary'),\n",
            "                data_root=\n",
            "                '/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(keep_ratio=True, scale=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Resize'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='BOE_Chiu_Dataset'),\n",
            "        ],\n",
            "        type='ConcatDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 19:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:36:31 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "12/14 19:36:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet50_v1c\n",
            "12/14 19:36:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n",
            "12/14 19:36:32 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([21, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 512, 1, 1]).\n",
            "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([21, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).\n",
            "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/14 19:36:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth\n",
            "12/14 19:36:32 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 19:36:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 19:36:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9960e-03  eta: 0:06:32  time: 2.0661  data_time: 0.0045  memory: 10303  loss: 0.3707  decode.loss_ce: 0.2115  decode.acc_seg: 98.9044  aux.loss_ce: 0.1591  aux.acc_seg: 98.9044\n",
            "12/14 19:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9915e-03  eta: 0:03:38  time: 0.3667  data_time: 0.0048  memory: 3276  loss: 0.0675  decode.loss_ce: 0.0456  decode.acc_seg: 98.4825  aux.loss_ce: 0.0219  aux.acc_seg: 98.4825\n",
            "12/14 19:37:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9871e-03  eta: 0:02:38  time: 0.3665  data_time: 0.0048  memory: 3276  loss: 0.0188  decode.loss_ce: 0.0126  decode.acc_seg: 99.9420  aux.loss_ce: 0.0062  aux.acc_seg: 99.9420\n",
            "12/14 19:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9826e-03  eta: 0:02:06  time: 0.3652  data_time: 0.0048  memory: 3276  loss: 0.0329  decode.loss_ce: 0.0233  decode.acc_seg: 99.9184  aux.loss_ce: 0.0097  aux.acc_seg: 99.9184\n",
            "12/14 19:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9782e-03  eta: 0:01:45  time: 0.3650  data_time: 0.0048  memory: 3276  loss: 0.0281  decode.loss_ce: 0.0189  decode.acc_seg: 99.7513  aux.loss_ce: 0.0092  aux.acc_seg: 99.7513\n",
            "12/14 19:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9737e-03  eta: 0:01:30  time: 0.3647  data_time: 0.0048  memory: 3276  loss: 0.0198  decode.loss_ce: 0.0116  decode.acc_seg: 99.2180  aux.loss_ce: 0.0082  aux.acc_seg: 99.2180\n",
            "12/14 19:37:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9693e-03  eta: 0:01:19  time: 0.3638  data_time: 0.0048  memory: 3276  loss: 0.0213  decode.loss_ce: 0.0127  decode.acc_seg: 99.7971  aux.loss_ce: 0.0085  aux.acc_seg: 99.7971\n",
            "12/14 19:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9648e-03  eta: 0:01:09  time: 0.3640  data_time: 0.0048  memory: 3276  loss: 0.0218  decode.loss_ce: 0.0128  decode.acc_seg: 99.9870  aux.loss_ce: 0.0090  aux.acc_seg: 99.9870\n",
            "12/14 19:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512_20231214_193548\n",
            "12/14 19:37:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9603e-03  eta: 0:01:00  time: 0.3635  data_time: 0.0049  memory: 3276  loss: 0.0208  decode.loss_ce: 0.0130  decode.acc_seg: 99.7040  aux.loss_ce: 0.0078  aux.acc_seg: 99.7040\n",
            "12/14 19:37:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9559e-03  eta: 0:00:53  time: 0.3667  data_time: 0.0047  memory: 3276  loss: 0.0222  decode.loss_ce: 0.0131  decode.acc_seg: 99.9886  aux.loss_ce: 0.0091  aux.acc_seg: 99.9886\n",
            "12/14 19:37:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9514e-03  eta: 0:00:46  time: 0.3652  data_time: 0.0049  memory: 3276  loss: 0.0204  decode.loss_ce: 0.0118  decode.acc_seg: 99.3057  aux.loss_ce: 0.0086  aux.acc_seg: 99.3057\n",
            "12/14 19:37:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9470e-03  eta: 0:00:40  time: 0.3662  data_time: 0.0047  memory: 3276  loss: 0.0192  decode.loss_ce: 0.0114  decode.acc_seg: 99.9466  aux.loss_ce: 0.0078  aux.acc_seg: 99.9466\n",
            "12/14 19:37:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9425e-03  eta: 0:00:34  time: 0.3685  data_time: 0.0049  memory: 3276  loss: 0.0125  decode.loss_ce: 0.0074  decode.acc_seg: 99.5209  aux.loss_ce: 0.0051  aux.acc_seg: 99.5209\n",
            "12/14 19:37:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9381e-03  eta: 0:00:29  time: 0.3639  data_time: 0.0047  memory: 3276  loss: 0.0129  decode.loss_ce: 0.0074  decode.acc_seg: 99.9199  aux.loss_ce: 0.0054  aux.acc_seg: 99.9199\n",
            "12/14 19:37:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9336e-03  eta: 0:00:23  time: 0.3651  data_time: 0.0049  memory: 3276  loss: 0.0113  decode.loss_ce: 0.0066  decode.acc_seg: 99.9504  aux.loss_ce: 0.0047  aux.acc_seg: 99.9504\n",
            "12/14 19:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9291e-03  eta: 0:00:18  time: 0.3651  data_time: 0.0047  memory: 3276  loss: 0.0178  decode.loss_ce: 0.0106  decode.acc_seg: 99.7253  aux.loss_ce: 0.0072  aux.acc_seg: 99.7253\n",
            "12/14 19:37:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9247e-03  eta: 0:00:13  time: 0.3685  data_time: 0.0049  memory: 3276  loss: 0.0167  decode.loss_ce: 0.0101  decode.acc_seg: 99.7910  aux.loss_ce: 0.0066  aux.acc_seg: 99.7910\n",
            "12/14 19:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9202e-03  eta: 0:00:09  time: 0.3683  data_time: 0.0047  memory: 3276  loss: 0.0176  decode.loss_ce: 0.0107  decode.acc_seg: 99.8932  aux.loss_ce: 0.0068  aux.acc_seg: 99.8932\n",
            "12/14 19:37:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9158e-03  eta: 0:00:04  time: 0.3665  data_time: 0.0047  memory: 3276  loss: 0.0190  decode.loss_ce: 0.0114  decode.acc_seg: 98.9174  aux.loss_ce: 0.0076  aux.acc_seg: 98.9174\n",
            "12/14 19:38:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9113e-03  eta: 0:00:00  time: 0.3650  data_time: 0.0049  memory: 3276  loss: 0.0099  decode.loss_ce: 0.0060  decode.acc_seg: 99.7917  aux.loss_ce: 0.0039  aux.acc_seg: 99.7917\n",
            "12/14 19:38:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 19:38:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:04  time: 0.3786  data_time: 0.0120  memory: 9053  \n",
            "12/14 19:38:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.0682  data_time: 0.0021  memory: 911  \n",
            "12/14 19:38:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 19:38:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.73 | 100.0 | 99.47 | 99.73  |   99.47   | 100.0  |\n",
            "| fluid |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 19:38:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 49.8700  mAcc: 50.0000  mIoU: 49.7300  mFscore: 99.7300  mPrecision: 99.4700  mRecall: 50.0000  data_time: 0.0066  time: 0.2092\n"
          ]
        }
      ],
      "source": [
        "\n",
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False, dataset_num=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. FCN Pretrained on VOC Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing fcn_r50-d8_4xb4-20k_voc12aug-512x512...\n",
            "\u001b[32mfcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth exists in /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped fcn_r50-d8_4xb4-20k_voc12aug-512x512.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !mim download mmsegmentation --config fcn_r50-d8_4xb4-20k_voc12aug-512x512 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:38:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/14 19:38:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_aug = dict(\n",
            "    ann_file='ImageSets/Segmentation/aug.txt',\n",
            "    data_prefix=dict(\n",
            "        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_train = dict(\n",
            "    ann_file='ImageSets/Segmentation/train.txt',\n",
            "    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=512,\n",
            "        concat_input=True,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=2,\n",
            "        type='FCNHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=20000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = [\n",
            "    'mDice',\n",
            "    'mIoU',\n",
            "    'mFscore',\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        datasets=[\n",
            "            dict(\n",
            "                ann_file='splits/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='image_png_256_gray',\n",
            "                    seg_map_path='fluid_png_256_binary'),\n",
            "                data_root=\n",
            "                '/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(keep_ratio=True, scale=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Resize'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='BOE_Chiu_Dataset'),\n",
            "            dict(\n",
            "                ann_file='splits/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='image_png_256_gray',\n",
            "                    seg_map_path='fluid_png_256_binary'),\n",
            "                data_root=\n",
            "                '/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(keep_ratio=True, scale=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Resize'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='BOE_Chiu_Dataset'),\n",
            "        ],\n",
            "        type='ConcatDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:38:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 19:38:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 19:38:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "12/14 19:38:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet50_v1c\n",
            "12/14 19:38:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n",
            "12/14 19:38:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([21, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 512, 1, 1]).\n",
            "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([21, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).\n",
            "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/14 19:38:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth\n",
            "12/14 19:38:46 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 19:38:46 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "12/14 19:38:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 19:38:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9960e-03  eta: 0:03:35  time: 1.1359  data_time: 0.0042  memory: 10161  loss: 0.3769  decode.loss_ce: 0.2191  decode.acc_seg: 98.9044  aux.loss_ce: 0.1578  aux.acc_seg: 98.9044\n",
            "12/14 19:38:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9915e-03  eta: 0:02:02  time: 0.2288  data_time: 0.0045  memory: 3072  loss: 0.0674  decode.loss_ce: 0.0454  decode.acc_seg: 98.4825  aux.loss_ce: 0.0221  aux.acc_seg: 98.4825\n",
            "12/14 19:39:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9871e-03  eta: 0:01:30  time: 0.2279  data_time: 0.0044  memory: 3072  loss: 0.0191  decode.loss_ce: 0.0129  decode.acc_seg: 99.9420  aux.loss_ce: 0.0062  aux.acc_seg: 99.9420\n",
            "12/14 19:39:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9826e-03  eta: 0:01:12  time: 0.2305  data_time: 0.0045  memory: 3072  loss: 0.0334  decode.loss_ce: 0.0242  decode.acc_seg: 99.9184  aux.loss_ce: 0.0092  aux.acc_seg: 99.9184\n",
            "12/14 19:39:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9782e-03  eta: 0:01:01  time: 0.2278  data_time: 0.0045  memory: 3072  loss: 0.0262  decode.loss_ce: 0.0173  decode.acc_seg: 99.7513  aux.loss_ce: 0.0089  aux.acc_seg: 99.7513\n",
            "12/14 19:39:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9737e-03  eta: 0:00:53  time: 0.2289  data_time: 0.0044  memory: 3072  loss: 0.0192  decode.loss_ce: 0.0108  decode.acc_seg: 99.2180  aux.loss_ce: 0.0083  aux.acc_seg: 99.2180\n",
            "12/14 19:39:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9693e-03  eta: 0:00:46  time: 0.2292  data_time: 0.0045  memory: 3072  loss: 0.0211  decode.loss_ce: 0.0125  decode.acc_seg: 99.7971  aux.loss_ce: 0.0086  aux.acc_seg: 99.7971\n",
            "12/14 19:39:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9648e-03  eta: 0:00:41  time: 0.2284  data_time: 0.0045  memory: 3072  loss: 0.0210  decode.loss_ce: 0.0119  decode.acc_seg: 99.9870  aux.loss_ce: 0.0091  aux.acc_seg: 99.9870\n",
            "12/14 19:39:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: fcn_r50-d8_4xb4-20k_voc12aug-512x512_20231214_193840\n",
            "12/14 19:39:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9603e-03  eta: 0:00:36  time: 0.2292  data_time: 0.0048  memory: 3072  loss: 0.0188  decode.loss_ce: 0.0110  decode.acc_seg: 99.7040  aux.loss_ce: 0.0078  aux.acc_seg: 99.7040\n",
            "12/14 19:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9559e-03  eta: 0:00:31  time: 0.2274  data_time: 0.0047  memory: 3072  loss: 0.0209  decode.loss_ce: 0.0120  decode.acc_seg: 99.9886  aux.loss_ce: 0.0090  aux.acc_seg: 99.9886\n",
            "12/14 19:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9514e-03  eta: 0:00:27  time: 0.2279  data_time: 0.0045  memory: 3072  loss: 0.0192  decode.loss_ce: 0.0108  decode.acc_seg: 99.3057  aux.loss_ce: 0.0084  aux.acc_seg: 99.3057\n",
            "12/14 19:39:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9470e-03  eta: 0:00:24  time: 0.2277  data_time: 0.0044  memory: 3072  loss: 0.0169  decode.loss_ce: 0.0098  decode.acc_seg: 99.9466  aux.loss_ce: 0.0071  aux.acc_seg: 99.9466\n",
            "12/14 19:39:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9425e-03  eta: 0:00:20  time: 0.2315  data_time: 0.0059  memory: 3072  loss: 0.0123  decode.loss_ce: 0.0073  decode.acc_seg: 99.5209  aux.loss_ce: 0.0051  aux.acc_seg: 99.5209\n",
            "12/14 19:39:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9381e-03  eta: 0:00:17  time: 0.2318  data_time: 0.0062  memory: 3072  loss: 0.0125  decode.loss_ce: 0.0073  decode.acc_seg: 99.9199  aux.loss_ce: 0.0051  aux.acc_seg: 99.9199\n",
            "12/14 19:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9336e-03  eta: 0:00:14  time: 0.2285  data_time: 0.0045  memory: 3072  loss: 0.0106  decode.loss_ce: 0.0062  decode.acc_seg: 99.9504  aux.loss_ce: 0.0044  aux.acc_seg: 99.9504\n",
            "12/14 19:39:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9291e-03  eta: 0:00:11  time: 0.2280  data_time: 0.0048  memory: 3072  loss: 0.0163  decode.loss_ce: 0.0096  decode.acc_seg: 99.7253  aux.loss_ce: 0.0068  aux.acc_seg: 99.7253\n",
            "12/14 19:39:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9247e-03  eta: 0:00:08  time: 0.2278  data_time: 0.0045  memory: 3072  loss: 0.0153  decode.loss_ce: 0.0090  decode.acc_seg: 99.7910  aux.loss_ce: 0.0063  aux.acc_seg: 99.7910\n",
            "12/14 19:39:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9202e-03  eta: 0:00:05  time: 0.2284  data_time: 0.0046  memory: 3072  loss: 0.0168  decode.loss_ce: 0.0104  decode.acc_seg: 99.8932  aux.loss_ce: 0.0065  aux.acc_seg: 99.8932\n",
            "12/14 19:39:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9158e-03  eta: 0:00:02  time: 0.2281  data_time: 0.0046  memory: 3072  loss: 0.0173  decode.loss_ce: 0.0103  decode.acc_seg: 98.9174  aux.loss_ce: 0.0069  aux.acc_seg: 98.9174\n",
            "12/14 19:39:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9113e-03  eta: 0:00:00  time: 0.2273  data_time: 0.0045  memory: 3072  loss: 0.0093  decode.loss_ce: 0.0055  decode.acc_seg: 99.7917  aux.loss_ce: 0.0038  aux.acc_seg: 99.7917\n",
            "12/14 19:39:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 19:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:03  time: 0.2525  data_time: 0.0130  memory: 8912  \n",
            "12/14 19:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.0445  data_time: 0.0019  memory: 639  \n",
            "12/14 19:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 19:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.73 | 100.0 | 99.47 | 99.73  |   99.47   | 100.0  |\n",
            "| fluid |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 19:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 49.8700  mAcc: 50.0000  mIoU: 49.7300  mFscore: 99.7300  mPrecision: 99.4700  mRecall: 50.0000  data_time: 0.0070  time: 0.1391\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_4xb4-20k_voc12aug-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False, dataset_num=2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
