{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "from pretrained_model import *\n",
        "from mmseg.registry import DATASETS\n",
        "from mmseg.datasets import BaseSegDataset\n",
        "%cd mmsegmentation\n",
        "\n",
        "root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
        "img_dir = 'image_png_256_gray'\n",
        "ann_dir = 'fluid_png_256_binary'\n",
        "\n",
        "classes = ('image', 'fluid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "@DATASETS.register_module()\n",
        "class BOE_Chiu_Dataset(BaseSegDataset):\n",
        "    METAINFO = dict(classes = classes)\n",
        "    def __init__(self,dataset=None, times=None, **kwargs):\n",
        "        super(BOE_Chiu_Dataset, self).__init__(img_suffix='.png', seg_map_suffix='.png', **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. UNET with FCN Head Trained on HRF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_fcn_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:28:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/14 03:28:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:28:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 03:28:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:28:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth\n",
            "12/14 03:28:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth\n",
            "12/14 03:28:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 03:28:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "12/14 03:28:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 03:29:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:02:07  time: 0.6723  data_time: 0.0043  memory: 10544  loss: 0.0798  decode.loss_ce: 0.0571  decode.acc_seg: 99.2973  aux.loss_ce: 0.0227  aux.acc_seg: 99.2973\n",
            "12/14 03:29:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:17  time: 0.1842  data_time: 0.0045  memory: 4703  loss: 0.0402  decode.loss_ce: 0.0276  decode.acc_seg: 99.8108  aux.loss_ce: 0.0127  aux.acc_seg: 99.8108\n",
            "12/14 03:29:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:00:58  time: 0.1846  data_time: 0.0045  memory: 4703  loss: 0.0426  decode.loss_ce: 0.0299  decode.acc_seg: 99.9931  aux.loss_ce: 0.0126  aux.acc_seg: 99.9931\n",
            "12/14 03:29:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:00:48  time: 0.1838  data_time: 0.0045  memory: 4703  loss: 0.0296  decode.loss_ce: 0.0203  decode.acc_seg: 99.3652  aux.loss_ce: 0.0093  aux.acc_seg: 99.3652\n",
            "12/14 03:29:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_fcn_4xb4-40k_hrf-256x256_20231214_032852\n",
            "12/14 03:29:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:00:42  time: 0.1845  data_time: 0.0048  memory: 4703  loss: 0.0242  decode.loss_ce: 0.0160  decode.acc_seg: 98.8808  aux.loss_ce: 0.0082  aux.acc_seg: 98.8808\n",
            "12/14 03:29:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:00:37  time: 0.1854  data_time: 0.0044  memory: 4703  loss: 0.0329  decode.loss_ce: 0.0230  decode.acc_seg: 99.7147  aux.loss_ce: 0.0099  aux.acc_seg: 99.7147\n",
            "12/14 03:29:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:00:33  time: 0.1835  data_time: 0.0044  memory: 4703  loss: 0.0220  decode.loss_ce: 0.0150  decode.acc_seg: 99.9893  aux.loss_ce: 0.0071  aux.acc_seg: 99.9893\n",
            "12/14 03:29:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:29  time: 0.1858  data_time: 0.0043  memory: 4703  loss: 0.0219  decode.loss_ce: 0.0150  decode.acc_seg: 100.0000  aux.loss_ce: 0.0069  aux.acc_seg: 100.0000\n",
            "12/14 03:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:26  time: 0.1856  data_time: 0.0046  memory: 4703  loss: 0.0240  decode.loss_ce: 0.0166  decode.acc_seg: 99.7917  aux.loss_ce: 0.0074  aux.acc_seg: 99.7917\n",
            "12/14 03:29:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:23  time: 0.1868  data_time: 0.0049  memory: 4703  loss: 0.0205  decode.loss_ce: 0.0139  decode.acc_seg: 99.8444  aux.loss_ce: 0.0066  aux.acc_seg: 99.8716\n",
            "12/14 03:29:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:20  time: 0.1873  data_time: 0.0050  memory: 4703  loss: 0.0188  decode.loss_ce: 0.0125  decode.acc_seg: 99.9031  aux.loss_ce: 0.0063  aux.acc_seg: 99.8894\n",
            "12/14 03:29:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:18  time: 0.1864  data_time: 0.0052  memory: 4703  loss: 0.0139  decode.loss_ce: 0.0088  decode.acc_seg: 99.7910  aux.loss_ce: 0.0051  aux.acc_seg: 99.7919\n",
            "12/14 03:29:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:15  time: 0.1873  data_time: 0.0048  memory: 4703  loss: 0.0161  decode.loss_ce: 0.0106  decode.acc_seg: 99.9405  aux.loss_ce: 0.0055  aux.acc_seg: 99.9468\n",
            "12/14 03:29:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:13  time: 0.1864  data_time: 0.0049  memory: 4703  loss: 0.0156  decode.loss_ce: 0.0102  decode.acc_seg: 99.5186  aux.loss_ce: 0.0054  aux.acc_seg: 99.5186\n",
            "12/14 03:29:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:10  time: 0.1855  data_time: 0.0044  memory: 4703  loss: 0.0169  decode.loss_ce: 0.0112  decode.acc_seg: 99.7955  aux.loss_ce: 0.0057  aux.acc_seg: 99.7505\n",
            "12/14 03:29:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:08  time: 0.1861  data_time: 0.0051  memory: 4703  loss: 0.0181  decode.loss_ce: 0.0120  decode.acc_seg: 99.3774  aux.loss_ce: 0.0061  aux.acc_seg: 99.4047\n",
            "12/14 03:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:06  time: 0.1841  data_time: 0.0045  memory: 4703  loss: 0.0135  decode.loss_ce: 0.0089  decode.acc_seg: 99.9466  aux.loss_ce: 0.0045  aux.acc_seg: 99.9460\n",
            "12/14 03:29:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:04  time: 0.1839  data_time: 0.0044  memory: 4703  loss: 0.0102  decode.loss_ce: 0.0067  decode.acc_seg: 99.7597  aux.loss_ce: 0.0035  aux.acc_seg: 99.7593\n",
            "12/14 03:29:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:02  time: 0.1864  data_time: 0.0047  memory: 4703  loss: 0.0102  decode.loss_ce: 0.0065  decode.acc_seg: 99.9550  aux.loss_ce: 0.0037  aux.acc_seg: 99.9491\n",
            "12/14 03:29:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.1855  data_time: 0.0045  memory: 4703  loss: 0.0210  decode.loss_ce: 0.0144  decode.acc_seg: 100.0000  aux.loss_ce: 0.0066  aux.acc_seg: 100.0000\n",
            "12/14 03:29:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 03:29:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:03  time: 0.3208  data_time: 0.0129  memory: 9011  \n",
            "12/14 03:29:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1224  data_time: 0.0023  memory: 372  \n",
            "12/14 03:29:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 03:29:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.73 | 100.0 | 99.47 | 99.73  |   99.47   | 100.0  |\n",
            "| fluid |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 03:29:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 49.8700  mAcc: 50.0000  mIoU: 49.7300  mFscore: 99.7300  mPrecision: 99.4700  mRecall: 50.0000  data_time: 0.0072  time: 0.2133\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_fcn_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. UNET with PSPNet Head Trained on HRF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing unet-s5-d16_pspnet_4xb4-40k_hrf-256x256...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.9/110.9 MiB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped unet-s5-d16_pspnet_4xb4-40k_hrf-256x256.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_pspnet_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:32:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:32:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=16,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        pool_scales=(\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "            6,\n",
            "        ),\n",
            "        type='PSPHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:32:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 03:32:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:32:47 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth\n",
            "12/14 03:32:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth\n",
            "12/14 03:32:48 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 03:32:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 03:32:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:01:38  time: 0.5177  data_time: 0.0044  memory: 9486  loss: 0.0809  decode.loss_ce: 0.0572  decode.acc_seg: 99.2973  aux.loss_ce: 0.0236  aux.acc_seg: 99.2973\n",
            "12/14 03:32:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:28  time: 0.4640  data_time: 0.0047  memory: 4607  loss: 0.0442  decode.loss_ce: 0.0299  decode.acc_seg: 99.8108  aux.loss_ce: 0.0143  aux.acc_seg: 99.8108\n",
            "12/14 03:33:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:01:21  time: 0.4638  data_time: 0.0050  memory: 4607  loss: 0.0431  decode.loss_ce: 0.0294  decode.acc_seg: 99.9931  aux.loss_ce: 0.0138  aux.acc_seg: 99.9931\n",
            "12/14 03:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:01:16  time: 0.4646  data_time: 0.0047  memory: 4607  loss: 0.0337  decode.loss_ce: 0.0238  decode.acc_seg: 99.3652  aux.loss_ce: 0.0099  aux.acc_seg: 99.3652\n",
            "12/14 03:33:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_pspnet_4xb4-40k_hrf-256x256_20231214_033205\n",
            "12/14 03:33:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:01:11  time: 0.4652  data_time: 0.0050  memory: 4607  loss: 0.0251  decode.loss_ce: 0.0175  decode.acc_seg: 98.8808  aux.loss_ce: 0.0076  aux.acc_seg: 98.8808\n",
            "12/14 03:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:01:06  time: 0.4650  data_time: 0.0052  memory: 4607  loss: 0.0339  decode.loss_ce: 0.0239  decode.acc_seg: 99.7168  aux.loss_ce: 0.0100  aux.acc_seg: 99.7147\n",
            "12/14 03:33:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:01:01  time: 0.4633  data_time: 0.0048  memory: 4607  loss: 0.0213  decode.loss_ce: 0.0143  decode.acc_seg: 99.9893  aux.loss_ce: 0.0070  aux.acc_seg: 99.9893\n",
            "12/14 03:33:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:56  time: 0.4634  data_time: 0.0047  memory: 4607  loss: 0.0242  decode.loss_ce: 0.0159  decode.acc_seg: 100.0000  aux.loss_ce: 0.0082  aux.acc_seg: 100.0000\n",
            "12/14 03:33:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:51  time: 0.4633  data_time: 0.0051  memory: 4607  loss: 0.0238  decode.loss_ce: 0.0160  decode.acc_seg: 99.7917  aux.loss_ce: 0.0078  aux.acc_seg: 99.7917\n",
            "12/14 03:33:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:46  time: 0.4649  data_time: 0.0047  memory: 4607  loss: 0.0201  decode.loss_ce: 0.0134  decode.acc_seg: 99.7433  aux.loss_ce: 0.0066  aux.acc_seg: 99.8444\n",
            "12/14 03:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:42  time: 0.4629  data_time: 0.0048  memory: 4607  loss: 0.0187  decode.loss_ce: 0.0119  decode.acc_seg: 99.9018  aux.loss_ce: 0.0067  aux.acc_seg: 99.9031\n",
            "12/14 03:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:37  time: 0.4655  data_time: 0.0054  memory: 4607  loss: 0.0130  decode.loss_ce: 0.0082  decode.acc_seg: 99.8686  aux.loss_ce: 0.0048  aux.acc_seg: 99.7910\n",
            "12/14 03:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:32  time: 0.4629  data_time: 0.0046  memory: 4607  loss: 0.0147  decode.loss_ce: 0.0094  decode.acc_seg: 99.9483  aux.loss_ce: 0.0053  aux.acc_seg: 99.9405\n",
            "12/14 03:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:28  time: 0.4623  data_time: 0.0048  memory: 4607  loss: 0.0157  decode.loss_ce: 0.0102  decode.acc_seg: 99.6620  aux.loss_ce: 0.0055  aux.acc_seg: 99.5186\n",
            "12/14 03:33:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:23  time: 0.4635  data_time: 0.0047  memory: 4607  loss: 0.0151  decode.loss_ce: 0.0095  decode.acc_seg: 99.8138  aux.loss_ce: 0.0056  aux.acc_seg: 99.7992\n",
            "12/14 03:34:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:18  time: 0.4641  data_time: 0.0047  memory: 4607  loss: 0.0180  decode.loss_ce: 0.0120  decode.acc_seg: 99.5224  aux.loss_ce: 0.0060  aux.acc_seg: 99.3774\n",
            "12/14 03:34:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:14  time: 0.4634  data_time: 0.0047  memory: 4607  loss: 0.0122  decode.loss_ce: 0.0076  decode.acc_seg: 99.9512  aux.loss_ce: 0.0046  aux.acc_seg: 99.9466\n",
            "12/14 03:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:09  time: 0.4647  data_time: 0.0046  memory: 4607  loss: 0.0091  decode.loss_ce: 0.0054  decode.acc_seg: 99.7644  aux.loss_ce: 0.0037  aux.acc_seg: 99.7597\n",
            "12/14 03:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:04  time: 0.4620  data_time: 0.0047  memory: 4607  loss: 0.0093  decode.loss_ce: 0.0058  decode.acc_seg: 99.9554  aux.loss_ce: 0.0035  aux.acc_seg: 99.9598\n",
            "12/14 03:34:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.4620  data_time: 0.0049  memory: 4607  loss: 0.0184  decode.loss_ce: 0.0117  decode.acc_seg: 100.0000  aux.loss_ce: 0.0066  aux.acc_seg: 100.0000\n",
            "12/14 03:34:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 03:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.1903  data_time: 0.0132  memory: 1592  \n",
            "12/14 03:34:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1505  data_time: 0.0026  memory: 372  \n",
            "12/14 03:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 03:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.73 | 99.98 | 99.47 | 99.73  |   99.49   | 99.98  |\n",
            "| fluid |  7.47 |  4.04 |  3.88 |  7.47  |   49.76   |  4.04  |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 03:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 53.6000  mAcc: 52.0100  mIoU: 51.6700  mFscore: 53.6000  mPrecision: 74.6200  mRecall: 52.0100  data_time: 0.0075  time: 0.1687\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_pspnet_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. UNET with DeepLabV3 Trained on HRF Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 MiB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/14 03:35:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=16,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='ASPPHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 03:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:35:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth\n",
            "12/14 03:35:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth\n",
            "12/14 03:35:09 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 03:35:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 03:35:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:01:25  time: 0.4497  data_time: 0.0045  memory: 7822  loss: 0.0893  decode.loss_ce: 0.0629  decode.acc_seg: 99.2973  aux.loss_ce: 0.0264  aux.acc_seg: 99.2973\n",
            "12/14 03:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:07  time: 0.3015  data_time: 0.0050  memory: 4642  loss: 0.0433  decode.loss_ce: 0.0295  decode.acc_seg: 99.8108  aux.loss_ce: 0.0137  aux.acc_seg: 99.8108\n",
            "12/14 03:35:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:00:59  time: 0.2982  data_time: 0.0048  memory: 4642  loss: 0.0456  decode.loss_ce: 0.0313  decode.acc_seg: 99.9931  aux.loss_ce: 0.0144  aux.acc_seg: 99.9931\n",
            "12/14 03:35:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:00:53  time: 0.2990  data_time: 0.0047  memory: 4642  loss: 0.0337  decode.loss_ce: 0.0234  decode.acc_seg: 99.3652  aux.loss_ce: 0.0103  aux.acc_seg: 99.3652\n",
            "12/14 03:35:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256_20231214_033426\n",
            "12/14 03:35:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:00:49  time: 0.3021  data_time: 0.0053  memory: 4642  loss: 0.0288  decode.loss_ce: 0.0206  decode.acc_seg: 98.8808  aux.loss_ce: 0.0082  aux.acc_seg: 98.8808\n",
            "12/14 03:35:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:00:45  time: 0.2993  data_time: 0.0048  memory: 4642  loss: 0.0374  decode.loss_ce: 0.0259  decode.acc_seg: 99.7108  aux.loss_ce: 0.0114  aux.acc_seg: 99.7147\n",
            "12/14 03:35:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:00:41  time: 0.3009  data_time: 0.0046  memory: 4642  loss: 0.0217  decode.loss_ce: 0.0140  decode.acc_seg: 99.9893  aux.loss_ce: 0.0077  aux.acc_seg: 99.9893\n",
            "12/14 03:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:38  time: 0.2986  data_time: 0.0047  memory: 4642  loss: 0.0248  decode.loss_ce: 0.0165  decode.acc_seg: 100.0000  aux.loss_ce: 0.0084  aux.acc_seg: 100.0000\n",
            "12/14 03:35:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:34  time: 0.2999  data_time: 0.0046  memory: 4642  loss: 0.0257  decode.loss_ce: 0.0173  decode.acc_seg: 99.4957  aux.loss_ce: 0.0084  aux.acc_seg: 99.7917\n",
            "12/14 03:35:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:31  time: 0.2997  data_time: 0.0048  memory: 4642  loss: 0.0242  decode.loss_ce: 0.0168  decode.acc_seg: 99.8442  aux.loss_ce: 0.0074  aux.acc_seg: 99.8480\n",
            "12/14 03:35:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:28  time: 0.2999  data_time: 0.0048  memory: 4642  loss: 0.0184  decode.loss_ce: 0.0119  decode.acc_seg: 99.8764  aux.loss_ce: 0.0065  aux.acc_seg: 99.8816\n",
            "12/14 03:35:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:24  time: 0.2982  data_time: 0.0045  memory: 4642  loss: 0.0133  decode.loss_ce: 0.0083  decode.acc_seg: 99.8600  aux.loss_ce: 0.0049  aux.acc_seg: 99.7913\n",
            "12/14 03:35:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:21  time: 0.2987  data_time: 0.0047  memory: 4642  loss: 0.0156  decode.loss_ce: 0.0097  decode.acc_seg: 99.8663  aux.loss_ce: 0.0058  aux.acc_seg: 99.9369\n",
            "12/14 03:35:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:18  time: 0.2998  data_time: 0.0047  memory: 4642  loss: 0.0167  decode.loss_ce: 0.0110  decode.acc_seg: 99.6031  aux.loss_ce: 0.0057  aux.acc_seg: 99.5436\n",
            "12/14 03:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:15  time: 0.2985  data_time: 0.0047  memory: 4642  loss: 0.0163  decode.loss_ce: 0.0104  decode.acc_seg: 99.7448  aux.loss_ce: 0.0059  aux.acc_seg: 99.7406\n",
            "12/14 03:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:12  time: 0.2985  data_time: 0.0047  memory: 4642  loss: 0.0184  decode.loss_ce: 0.0126  decode.acc_seg: 99.5214  aux.loss_ce: 0.0059  aux.acc_seg: 99.4762\n",
            "12/14 03:36:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:09  time: 0.2976  data_time: 0.0048  memory: 4642  loss: 0.0128  decode.loss_ce: 0.0082  decode.acc_seg: 99.9498  aux.loss_ce: 0.0046  aux.acc_seg: 99.9466\n",
            "12/14 03:36:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:06  time: 0.3011  data_time: 0.0050  memory: 4642  loss: 0.0094  decode.loss_ce: 0.0057  decode.acc_seg: 99.7507  aux.loss_ce: 0.0037  aux.acc_seg: 99.7599\n",
            "12/14 03:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:03  time: 0.2988  data_time: 0.0047  memory: 4642  loss: 0.0097  decode.loss_ce: 0.0060  decode.acc_seg: 99.9435  aux.loss_ce: 0.0037  aux.acc_seg: 99.9548\n",
            "12/14 03:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.2979  data_time: 0.0048  memory: 4642  loss: 0.0181  decode.loss_ce: 0.0118  decode.acc_seg: 100.0000  aux.loss_ce: 0.0063  aux.acc_seg: 100.0000\n",
            "12/14 03:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 03:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.1785  data_time: 0.0138  memory: 1151  \n",
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1488  data_time: 0.0023  memory: 373  \n",
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.75 | 99.98 | 99.51 | 99.75  |   99.52   | 99.98  |\n",
            "| fluid | 19.18 | 10.94 | 10.61 | 19.18  |   77.55   | 10.94  |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.5100  mDice: 59.4600  mAcc: 55.4600  mIoU: 55.0600  mFscore: 59.4600  mPrecision: 88.5400  mRecall: 55.4600  data_time: 0.0076  time: 0.1621\n"
          ]
        }
      ],
      "source": [
        "\n",
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. PSNET Trained on Postdam Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing pspnet_r50-d8_4xb4-80k_potsdam-512x512...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.1/187.1 MiB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped pspnet_r50-d8_4xb4-80k_potsdam-512x512.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !mim download mmsegmentation --config pspnet_r50-d8_4xb4-80k_potsdam-512x512 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=512,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        pool_scales=(\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "            6,\n",
            "        ),\n",
            "        type='PSPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=80000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 03:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:36:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "12/14 03:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: open-mmlab://resnet50_v1c\n",
            "12/14 03:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by openmmlab backend from path: open-mmlab://resnet50_v1c\n",
            "12/14 03:36:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([6, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 512, 1, 1]).\n",
            "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for auxiliary_head.conv_seg.weight: copying a param with shape torch.Size([6, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).\n",
            "size mismatch for auxiliary_head.conv_seg.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/14 03:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth\n",
            "12/14 03:36:57 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/14 03:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/14 03:37:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9990e-03  eta: 0:03:31  time: 1.1154  data_time: 0.0047  memory: 11247  loss: 0.6101  decode.loss_ce: 0.3875  decode.acc_seg: 99.2973  aux.loss_ce: 0.2226  aux.acc_seg: 99.2973\n",
            "12/14 03:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9979e-03  eta: 0:02:03  time: 0.2565  data_time: 0.0051  memory: 3343  loss: 0.1122  decode.loss_ce: 0.0418  decode.acc_seg: 99.8108  aux.loss_ce: 0.0704  aux.acc_seg: 99.8108\n",
            "12/14 03:37:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9968e-03  eta: 0:01:32  time: 0.2569  data_time: 0.0048  memory: 3343  loss: 0.0510  decode.loss_ce: 0.0244  decode.acc_seg: 99.9931  aux.loss_ce: 0.0267  aux.acc_seg: 99.9931\n",
            "12/14 03:37:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9957e-03  eta: 0:01:15  time: 0.2564  data_time: 0.0050  memory: 3343  loss: 0.0282  decode.loss_ce: 0.0130  decode.acc_seg: 99.3652  aux.loss_ce: 0.0152  aux.acc_seg: 99.3652\n",
            "12/14 03:37:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: pspnet_r50-d8_4xb4-80k_potsdam-512x512_20231214_033615\n",
            "12/14 03:37:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9945e-03  eta: 0:01:04  time: 0.2565  data_time: 0.0051  memory: 3343  loss: 0.0214  decode.loss_ce: 0.0105  decode.acc_seg: 98.8808  aux.loss_ce: 0.0109  aux.acc_seg: 98.8808\n",
            "12/14 03:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9934e-03  eta: 0:00:55  time: 0.2568  data_time: 0.0049  memory: 3343  loss: 0.0284  decode.loss_ce: 0.0159  decode.acc_seg: 99.7147  aux.loss_ce: 0.0125  aux.acc_seg: 99.7147\n",
            "12/14 03:37:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9923e-03  eta: 0:00:49  time: 0.2590  data_time: 0.0051  memory: 3343  loss: 0.0193  decode.loss_ce: 0.0103  decode.acc_seg: 99.9893  aux.loss_ce: 0.0090  aux.acc_seg: 99.9893\n",
            "12/14 03:37:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9912e-03  eta: 0:00:43  time: 0.2592  data_time: 0.0049  memory: 3343  loss: 0.0186  decode.loss_ce: 0.0097  decode.acc_seg: 100.0000  aux.loss_ce: 0.0088  aux.acc_seg: 100.0000\n",
            "12/14 03:37:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9901e-03  eta: 0:00:38  time: 0.2560  data_time: 0.0052  memory: 3343  loss: 0.0233  decode.loss_ce: 0.0137  decode.acc_seg: 99.7917  aux.loss_ce: 0.0096  aux.acc_seg: 99.7917\n",
            "12/14 03:37:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9890e-03  eta: 0:00:34  time: 0.2583  data_time: 0.0051  memory: 3343  loss: 0.0200  decode.loss_ce: 0.0118  decode.acc_seg: 99.8444  aux.loss_ce: 0.0082  aux.acc_seg: 99.8444\n",
            "12/14 03:37:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9879e-03  eta: 0:00:30  time: 0.2554  data_time: 0.0049  memory: 3343  loss: 0.0196  decode.loss_ce: 0.0117  decode.acc_seg: 99.9031  aux.loss_ce: 0.0078  aux.acc_seg: 99.9031\n",
            "12/14 03:37:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9867e-03  eta: 0:00:26  time: 0.2577  data_time: 0.0052  memory: 3343  loss: 0.0128  decode.loss_ce: 0.0069  decode.acc_seg: 99.7910  aux.loss_ce: 0.0058  aux.acc_seg: 99.7910\n",
            "12/14 03:37:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9856e-03  eta: 0:00:22  time: 0.2552  data_time: 0.0049  memory: 3343  loss: 0.0153  decode.loss_ce: 0.0089  decode.acc_seg: 99.9405  aux.loss_ce: 0.0064  aux.acc_seg: 99.9405\n",
            "12/14 03:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9845e-03  eta: 0:00:19  time: 0.2586  data_time: 0.0049  memory: 3343  loss: 0.0155  decode.loss_ce: 0.0092  decode.acc_seg: 99.5186  aux.loss_ce: 0.0063  aux.acc_seg: 99.5186\n",
            "12/14 03:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9834e-03  eta: 0:00:15  time: 0.2574  data_time: 0.0051  memory: 3343  loss: 0.0159  decode.loss_ce: 0.0096  decode.acc_seg: 99.7955  aux.loss_ce: 0.0063  aux.acc_seg: 99.7955\n",
            "12/14 03:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9823e-03  eta: 0:00:12  time: 0.2580  data_time: 0.0049  memory: 3343  loss: 0.0188  decode.loss_ce: 0.0117  decode.acc_seg: 99.3774  aux.loss_ce: 0.0071  aux.acc_seg: 99.3774\n",
            "12/14 03:37:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9812e-03  eta: 0:00:09  time: 0.2549  data_time: 0.0049  memory: 3343  loss: 0.0132  decode.loss_ce: 0.0079  decode.acc_seg: 99.9466  aux.loss_ce: 0.0052  aux.acc_seg: 99.9466\n",
            "12/14 03:37:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9801e-03  eta: 0:00:06  time: 0.2574  data_time: 0.0048  memory: 3343  loss: 0.0097  decode.loss_ce: 0.0054  decode.acc_seg: 99.7597  aux.loss_ce: 0.0042  aux.acc_seg: 99.7597\n",
            "12/14 03:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9789e-03  eta: 0:00:03  time: 0.2567  data_time: 0.0049  memory: 3343  loss: 0.0098  decode.loss_ce: 0.0056  decode.acc_seg: 99.9550  aux.loss_ce: 0.0042  aux.acc_seg: 99.9550\n",
            "12/14 03:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9778e-03  eta: 0:00:00  time: 0.2555  data_time: 0.0048  memory: 3343  loss: 0.0217  decode.loss_ce: 0.0142  decode.acc_seg: 100.0000  aux.loss_ce: 0.0075  aux.acc_seg: 100.0000\n",
            "12/14 03:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.2216  data_time: 0.0144  memory: 9266  \n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.0466  data_time: 0.0023  memory: 724  \n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.73 | 100.0 | 99.47 | 99.73  |   99.47   | 100.0  |\n",
            "| fluid |  0.0  |  0.0  |  0.0  |  nan   |    nan    |  0.0   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/14 03:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 49.8700  mAcc: 50.0000  mIoU: 49.7300  mFscore: 99.7300  mPrecision: 99.4700  mRecall: 50.0000  data_time: 0.0078  time: 0.1263\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4xb4-80k_potsdam-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_r50-d8_4x4_512x512_80k_potsdam_20211219_043541-2dd5fe67.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. DeepLabV3 Trained on VOC Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512...\n",
            "\u001b[32mdeeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth exists in /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!mim download mmsegmentation --config deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:42:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/14 03:42:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_aug = dict(\n",
            "    ann_file='ImageSets/Segmentation/aug.txt',\n",
            "    data_prefix=dict(\n",
            "        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_train = dict(\n",
            "    ann_file='ImageSets/Segmentation/train.txt',\n",
            "    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=512,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='ASPPHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=20000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        datasets=[\n",
            "            dict(\n",
            "                ann_file='ImageSets/Segmentation/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='JPEGImages', seg_map_path='SegmentationClass'),\n",
            "                data_root='data/VOCdevkit/VOC2012',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(\n",
            "                        keep_ratio=True,\n",
            "                        ratio_range=(\n",
            "                            0.5,\n",
            "                            2.0,\n",
            "                        ),\n",
            "                        scale=(\n",
            "                            2048,\n",
            "                            512,\n",
            "                        ),\n",
            "                        type='RandomResize'),\n",
            "                    dict(\n",
            "                        cat_max_ratio=0.75,\n",
            "                        crop_size=(\n",
            "                            512,\n",
            "                            512,\n",
            "                        ),\n",
            "                        type='RandomCrop'),\n",
            "                    dict(prob=0.5, type='RandomFlip'),\n",
            "                    dict(type='PhotoMetricDistortion'),\n",
            "                    dict(size=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Pad'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='PascalVOCDataset'),\n",
            "            dict(\n",
            "                ann_file='ImageSets/Segmentation/aug.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='JPEGImages',\n",
            "                    seg_map_path='SegmentationClassAug'),\n",
            "                data_root='data/VOCdevkit/VOC2012',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(\n",
            "                        keep_ratio=True,\n",
            "                        ratio_range=(\n",
            "                            0.5,\n",
            "                            2.0,\n",
            "                        ),\n",
            "                        scale=(\n",
            "                            2048,\n",
            "                            512,\n",
            "                        ),\n",
            "                        type='RandomResize'),\n",
            "                    dict(\n",
            "                        cat_max_ratio=0.75,\n",
            "                        crop_size=(\n",
            "                            512,\n",
            "                            512,\n",
            "                        ),\n",
            "                        type='RandomCrop'),\n",
            "                    dict(prob=0.5, type='RandomFlip'),\n",
            "                    dict(type='PhotoMetricDistortion'),\n",
            "                    dict(size=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Pad'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='PascalVOCDataset'),\n",
            "        ],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:42:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 03:42:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "BaseSegDataset.__init__() got an unexpected keyword argument 'datasets'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m config_py_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512.py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m pretrained_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mann_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_py_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspaces/ECE661GroupProject_TransferLearning/pretrained_model.py:130\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_root, img_dir, fluid_dir, config_py_path, pth_path, verbose)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mpretty_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m runner \u001b[38;5;241m=\u001b[39m Runner\u001b[38;5;241m.\u001b[39mfrom_cfg(cfg)\n\u001b[0;32m--> 130\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/runner.py:1728\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`self._train_loop` should not be None when calling train \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod. Please provide `train_dataloader`, `train_cfg`, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`optimizer` and `param_scheduler` arguments when \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitializing runner.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1728\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_train_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# `build_optimizer` should be called before `build_param_scheduler`\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m#  because the latter depends on the former\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_optim_wrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_wrapper)\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/runner.py:1520\u001b[0m, in \u001b[0;36mRunner.build_train_loop\u001b[0;34m(self, loop)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly one of `type` or `by_epoch` can exist in `loop_cfg`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m loop_cfg:\n\u001b[0;32m-> 1520\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[43mLOOPS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1525\u001b[0m     by_epoch \u001b[38;5;241m=\u001b[39m loop_cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/registry/registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/registry/build_functions.py:121\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    119\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[1;32m    125\u001b[0m     print_log(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    130\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/loops.py:219\u001b[0m, in \u001b[0;36mIterBasedTrainLoop.__init__\u001b[0;34m(self, runner, dataloader, max_iters, val_begin, val_interval, dynamic_intervals)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    213\u001b[0m         runner,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         val_interval: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m    218\u001b[0m         dynamic_intervals: Optional[List[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(max_iters)\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iters \u001b[38;5;241m==\u001b[39m max_iters, \\\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`max_iters` should be a integer number, but get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_iters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/base_loop.py:26\u001b[0m, in \u001b[0;36mBaseLoop.__init__\u001b[0;34m(self, runner, dataloader)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataloader, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Determine whether or not different ranks use different seed.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     diff_rank_seed \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39m_randomness_cfg\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_rank_seed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff_rank_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiff_rank_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m dataloader\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/runner.py:1370\u001b[0m, in \u001b[0;36mRunner.build_dataloader\u001b[0;34m(dataloader, seed, diff_rank_seed)\u001b[0m\n\u001b[1;32m   1368\u001b[0m dataset_cfg \u001b[38;5;241m=\u001b[39m dataloader_cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset_cfg, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m-> 1370\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDATASETS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_init\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1372\u001b[0m         dataset\u001b[38;5;241m.\u001b[39mfull_init()\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/registry/registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/registry/build_functions.py:121\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    119\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[1;32m    125\u001b[0m     print_log(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    130\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
            "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mBOE_Chiu_Dataset.__init__\u001b[0;34m(self, dataset, times, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBOE_Chiu_Dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_map_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: BaseSegDataset.__init__() got an unexpected keyword argument 'datasets'"
          ]
        }
      ],
      "source": [
        "\n",
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_4xb4-20k_voc12aug-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_r50-d8_512x512_20k_voc12aug_20200617_010906-596905ef.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. FCN Trained on VOC Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !mim download mmsegmentation --config unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/14 03:40:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/14 03:40:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    512,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        512,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_aug = dict(\n",
            "    ann_file='ImageSets/Segmentation/aug.txt',\n",
            "    data_prefix=dict(\n",
            "        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_train = dict(\n",
            "    ann_file='ImageSets/Segmentation/train.txt',\n",
            "    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),\n",
            "    data_root='data/VOCdevkit/VOC2012',\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(type='LoadAnnotations'),\n",
            "        dict(\n",
            "            keep_ratio=True,\n",
            "            ratio_range=(\n",
            "                0.5,\n",
            "                2.0,\n",
            "            ),\n",
            "            scale=(\n",
            "                2048,\n",
            "                512,\n",
            "            ),\n",
            "            type='RandomResize'),\n",
            "        dict(cat_max_ratio=0.75, crop_size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='RandomCrop'),\n",
            "        dict(prob=0.5, type='RandomFlip'),\n",
            "        dict(type='PhotoMetricDistortion'),\n",
            "        dict(size=(\n",
            "            512,\n",
            "            512,\n",
            "        ), type='Pad'),\n",
            "        dict(type='PackSegInputs'),\n",
            "    ],\n",
            "    type='PascalVOCDataset')\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=256,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=1024,\n",
            "        in_index=2,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        contract_dilation=True,\n",
            "        depth=50,\n",
            "        dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            2,\n",
            "            4,\n",
            "        ),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=4,\n",
            "        out_indices=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        strides=(\n",
            "            1,\n",
            "            2,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        style='pytorch',\n",
            "        type='ResNetV1c'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            512,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=512,\n",
            "        concat_input=True,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=2048,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=2,\n",
            "        type='FCNHead'),\n",
            "    pretrained='open-mmlab://resnet50_v1c',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=20000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        datasets=[\n",
            "            dict(\n",
            "                ann_file='ImageSets/Segmentation/train.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='JPEGImages', seg_map_path='SegmentationClass'),\n",
            "                data_root='data/VOCdevkit/VOC2012',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(\n",
            "                        keep_ratio=True,\n",
            "                        ratio_range=(\n",
            "                            0.5,\n",
            "                            2.0,\n",
            "                        ),\n",
            "                        scale=(\n",
            "                            2048,\n",
            "                            512,\n",
            "                        ),\n",
            "                        type='RandomResize'),\n",
            "                    dict(\n",
            "                        cat_max_ratio=0.75,\n",
            "                        crop_size=(\n",
            "                            512,\n",
            "                            512,\n",
            "                        ),\n",
            "                        type='RandomCrop'),\n",
            "                    dict(prob=0.5, type='RandomFlip'),\n",
            "                    dict(type='PhotoMetricDistortion'),\n",
            "                    dict(size=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Pad'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='PascalVOCDataset'),\n",
            "            dict(\n",
            "                ann_file='ImageSets/Segmentation/aug.txt',\n",
            "                data_prefix=dict(\n",
            "                    img_path='JPEGImages',\n",
            "                    seg_map_path='SegmentationClassAug'),\n",
            "                data_root='data/VOCdevkit/VOC2012',\n",
            "                pipeline=[\n",
            "                    dict(type='LoadImageFromFile'),\n",
            "                    dict(type='LoadAnnotations'),\n",
            "                    dict(\n",
            "                        keep_ratio=True,\n",
            "                        ratio_range=(\n",
            "                            0.5,\n",
            "                            2.0,\n",
            "                        ),\n",
            "                        scale=(\n",
            "                            2048,\n",
            "                            512,\n",
            "                        ),\n",
            "                        type='RandomResize'),\n",
            "                    dict(\n",
            "                        cat_max_ratio=0.75,\n",
            "                        crop_size=(\n",
            "                            512,\n",
            "                            512,\n",
            "                        ),\n",
            "                        type='RandomCrop'),\n",
            "                    dict(prob=0.5, type='RandomFlip'),\n",
            "                    dict(type='PhotoMetricDistortion'),\n",
            "                    dict(size=(\n",
            "                        512,\n",
            "                        512,\n",
            "                    ), type='Pad'),\n",
            "                    dict(type='PackSegInputs'),\n",
            "                ],\n",
            "                type='PascalVOCDataset'),\n",
            "        ],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n",
            "12/14 03:40:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/14 03:40:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "BaseSegDataset.__init__() got an unexpected keyword argument 'datasets'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m config_py_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_4xb4-20k_voc12aug-512x512.py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m pretrained_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mann_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_py_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspaces/ECE661GroupProject_TransferLearning/pretrained_model.py:130\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_root, img_dir, fluid_dir, config_py_path, pth_path, verbose)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mpretty_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m runner \u001b[38;5;241m=\u001b[39m Runner\u001b[38;5;241m.\u001b[39mfrom_cfg(cfg)\n\u001b[0;32m--> 130\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/runner.py:1728\u001b[0m, in \u001b[0;36mRunner.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`self._train_loop` should not be None when calling train \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1724\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod. Please provide `train_dataloader`, `train_cfg`, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1725\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`optimizer` and `param_scheduler` arguments when \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitializing runner.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1728\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_train_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# `build_optimizer` should be called before `build_param_scheduler`\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m#  because the latter depends on the former\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_optim_wrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_wrapper)\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/runner.py:1520\u001b[0m, in \u001b[0;36mRunner.build_train_loop\u001b[0;34m(self, loop)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly one of `type` or `by_epoch` can exist in `loop_cfg`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m loop_cfg:\n\u001b[0;32m-> 1520\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[43mLOOPS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1525\u001b[0m     by_epoch \u001b[38;5;241m=\u001b[39m loop_cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/registry/registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/registry/build_functions.py:121\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    119\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[1;32m    125\u001b[0m     print_log(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    130\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/loops.py:219\u001b[0m, in \u001b[0;36mIterBasedTrainLoop.__init__\u001b[0;34m(self, runner, dataloader, max_iters, val_begin, val_interval, dynamic_intervals)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    213\u001b[0m         runner,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         val_interval: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m    218\u001b[0m         dynamic_intervals: Optional[List[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(max_iters)\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_iters \u001b[38;5;241m==\u001b[39m max_iters, \\\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`max_iters` should be a integer number, but get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_iters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/base_loop.py:26\u001b[0m, in \u001b[0;36mBaseLoop.__init__\u001b[0;34m(self, runner, dataloader)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataloader, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Determine whether or not different ranks use different seed.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     diff_rank_seed \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39m_randomness_cfg\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiff_rank_seed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff_rank_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiff_rank_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m dataloader\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/runner/runner.py:1370\u001b[0m, in \u001b[0;36mRunner.build_dataloader\u001b[0;34m(dataloader, seed, diff_rank_seed)\u001b[0m\n\u001b[1;32m   1368\u001b[0m dataset_cfg \u001b[38;5;241m=\u001b[39m dataloader_cfg\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset_cfg, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m-> 1370\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDATASETS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_init\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1372\u001b[0m         dataset\u001b[38;5;241m.\u001b[39mfull_init()\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/registry/registry.py:570\u001b[0m, in \u001b[0;36mRegistry.build\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg: \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    549\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build an instance.\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Build an instance by calling :attr:`build_func`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03m        >>> model = MODELS.build(cfg)\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/registry/build_functions.py:121\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m    119\u001b[0m     obj \u001b[38;5;241m=\u001b[39m obj_cls\u001b[38;5;241m.\u001b[39mget_instance(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (inspect\u001b[38;5;241m.\u001b[39misclass(obj_cls) \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misfunction(obj_cls)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mismethod(obj_cls)):\n\u001b[1;32m    125\u001b[0m     print_log(\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instance is built from \u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# type: ignore # noqa: E501\u001b[39;00m\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistry, and its implementation can be found in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    130\u001b[0m         level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n",
            "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mBOE_Chiu_Dataset.__init__\u001b[0;34m(self, dataset, times, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mBOE_Chiu_Dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_map_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: BaseSegDataset.__init__() got an unexpected keyword argument 'datasets'"
          ]
        }
      ],
      "source": [
        "\n",
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_4xb4-20k_voc12aug-512x512.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_r50-d8_512x512_20k_voc12aug_20200617_010715-52dc5306.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
