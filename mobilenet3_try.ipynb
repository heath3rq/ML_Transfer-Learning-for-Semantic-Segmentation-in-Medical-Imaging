{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVmnaxFJvsb8"
      },
      "source": [
        "# MMSegmentation Tutorial\n",
        "Welcome to MMSegmentation!\n",
        "\n",
        "In this tutorial, we demo\n",
        "* How to do inference with MMSeg trained weight\n",
        "* How to train on your own dataset and visualize the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS8YHrEhbpas"
      },
      "source": [
        "## Install MMSegmentation\n",
        "This step may take several minutes.\n",
        "\n",
        "We use PyTorch 1.12 and CUDA 11.3 for this tutorial. You may install other versions by change the version number in pip install command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWyLrLYaNEaL",
        "outputId": "9abfeccf-bb4d-4295-dd60-d86aa827ba4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ki3WUBjKbutg",
        "outputId": "7ad04e6b-4cbe-492e-e503-f60c6c202d8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m984.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.7)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.7.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.5.1)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.66.1)\n",
            "Collecting openxlab (from opendatalab->openmim)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.9/298.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.23.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from openmim)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from opendatalab->openmim)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun-python-sdk-core-2.14.0.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (41.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\n",
            "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=2992f3410ce6ad4da96d88b1b69e3629a93e55518deb7925e69d4da4291646d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.14.0-py3-none-any.whl size=535289 sha256=e2c3ffa9d1885c1d313bb71be278983492337a12d997d3b474228a6bb29ab869\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/3c/68/b7eab618d9f1d5e7d386296f1e07e2cf36aaa1eb5161885038\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=e698a93f09ea94f9942ed4a44cdbb1a6a65997bc1229e9c04cf0500e40e1bf60\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: crcmod, urllib3, tqdm, setuptools, pycryptodome, ordered-set, jmespath, colorama, rich, requests, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.32 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.14.0 aliyun-python-sdk-kms-2.16.2 colorama-0.4.6 crcmod-1.7 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.31 ordered-set-4.1.0 oss2-2.17.0 pycryptodome-3.19.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2 urllib3-1.26.18\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmengine\n",
            "  Downloading mmengine-0.10.1-py3-none-any.whl (450 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.3/450.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmengine)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.23.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.3.0)\n",
            "Collecting yapf (from mmengine)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n",
            "Installing collected packages: addict, yapf, mmengine\n",
            "Successfully installed addict-2.4.0 mmengine-0.10.1 yapf-0.40.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmcv>=2.0.0rc1\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (99.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc1) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc1) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc1) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc1) (23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc1) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc1) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc1) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv>=2.0.0rc1) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc1) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc1) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv>=2.0.0rc1) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0rc1) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install PyTorch\n",
        "!conda install pytorch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0 cudatoolkit=11.3 -c pytorch\n",
        "# Install mim\n",
        "!pip install -U openmim\n",
        "# Install mmengine\n",
        "!mim install mmengine\n",
        "# Install MMCV\n",
        "!mim install 'mmcv >= 2.0.0rc1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR-hHRvbNJJZ",
        "outputId": "6b957884-f5c7-46d7-fbc1-6c72f9ad04e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'mmsegmentation'...\n",
            "remote: Enumerating objects: 16316, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 16316 (delta 4), reused 16 (delta 0), pack-reused 16289\u001b[K\n",
            "Receiving objects: 100% (16316/16316), 23.22 MiB | 19.34 MiB/s, done.\n",
            "Resolving deltas: 100% (11377/11377), done.\n",
            "/content/mmsegmentation\n",
            "Obtaining file:///content/mmsegmentation\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.2.1) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.2.1) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.2.1) (23.2)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.2.1) (3.9.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmsegmentation==1.2.1) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.2.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.2.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.2.1) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.2.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.2.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.2.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmsegmentation==1.2.1) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->mmsegmentation==1.2.1) (0.2.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.2.1) (1.16.0)\n",
            "Installing collected packages: mmsegmentation\n",
            "  Running setup.py develop for mmsegmentation\n",
            "Successfully installed mmsegmentation-1.2.1\n"
          ]
        }
      ],
      "source": [
        "!rm -rf mmsegmentation\n",
        "!git clone -b main https://github.com/open-mmlab/mmsegmentation.git\n",
        "%cd mmsegmentation\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAE_h7XhPT7d",
        "outputId": "1e813c38-bd00-473d-af5c-57abdda0c7c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0+cu118 True\n",
            "1.2.1\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMSegmentation installation\n",
        "import mmseg\n",
        "print(mmseg.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta51clKX4cwM"
      },
      "source": [
        "## Finetune a semantic segmentation model on a new dataset\n",
        "\n",
        "To finetune on a customized dataset, the following steps are necessary.\n",
        "1. Add a new dataset class.\n",
        "2. Create a config file accordingly.\n",
        "3. Perform training and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcZg6x_K5Zs3"
      },
      "source": [
        "### Add a new dataset\n",
        "\n",
        "Datasets in MMSegmentation require image and semantic segmentation maps to be placed in folders with the same prefix. To support a new dataset, we may need to modify the original file structure.\n",
        "\n",
        "In this tutorial, we give an example of converting the dataset. You may refer to [docs](https://github.com/open-mmlab/mmsegmentation/blob/master/docs/en/tutorials/customize_datasets.md#customize-datasets-by-reorganizing-data) for details about dataset reorganization.\n",
        "\n",
        "We use [Stanford Background Dataset](http://dags.stanford.edu/projects/scenedataset.html) as an example. The dataset contains 715 images chosen from existing public datasets [LabelMe](http://labelme.csail.mit.edu), [MSRC](http://research.microsoft.com/en-us/projects/objectclassrecognition), [PASCAL VOC](http://pascallin.ecs.soton.ac.uk/challenges/VOC) and [Geometric Context](http://www.cs.illinois.edu/homes/dhoiem/). Images from these datasets are mainly outdoor scenes, each containing approximately 320-by-240 pixels.\n",
        "In this tutorial, we use the region annotations as labels. There are 8 classes in total, i.e. sky, tree, road, grass, water, building, mountain, and foreground object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFIt7MHq5Wls"
      },
      "outputs": [],
      "source": [
        "# download and unzip\n",
        "!wget http://dags.stanford.edu/data/iccv09Data.tar.gz -O stanford_background.tar.gz\n",
        "!tar xf stanford_background.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78LIci7F9WWI"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the dataset\n",
        "import mmcv\n",
        "import mmengine\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "img = mmcv.imread('iccv09Data/images/6000124.jpg')\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(mmcv.bgr2rgb(img))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5mNQuc2GsVE"
      },
      "source": [
        "We need to convert the annotation into semantic map format as an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnGZfribFHCx"
      },
      "outputs": [],
      "source": [
        "# define dataset root and directory for images and annotations\n",
        "data_root = 'iccv09Data'\n",
        "img_dir = 'images'\n",
        "ann_dir = 'labels'\n",
        "# define class and palette for better visualization\n",
        "classes = ('sky', 'tree', 'road', 'grass', 'water', 'bldg', 'mntn', 'fg obj')\n",
        "palette = [[128, 128, 128], [129, 127, 38], [120, 69, 125], [53, 125, 34],\n",
        "           [0, 11, 123], [118, 20, 12], [122, 81, 25], [241, 134, 51]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEZqu5DCfPDU"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# convert dataset annotation to semantic segmentation map\n",
        "for file in mmengine.scandir(osp.join(data_root, ann_dir), suffix='.regions.txt'):\n",
        "  seg_map = np.loadtxt(osp.join(data_root, ann_dir, file)).astype(np.uint8)\n",
        "  seg_img = Image.fromarray(seg_map).convert('P')\n",
        "  seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
        "  seg_img.save(osp.join(data_root, ann_dir, file.replace('.regions.txt',\n",
        "                                                         '.png')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MCSS9ABfSks"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the segmentation map we got\n",
        "import matplotlib.patches as mpatches\n",
        "img = Image.open('iccv09Data/labels/6000124.png')\n",
        "plt.figure(figsize=(8, 6))\n",
        "im = plt.imshow(np.array(img.convert('RGB')))\n",
        "\n",
        "# create a patch (proxy artist) for every color\n",
        "patches = [mpatches.Patch(color=np.array(palette[i])/255.,\n",
        "                          label=classes[i]) for i in range(8)]\n",
        "# put those patched as legend-handles into the legend\n",
        "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.,\n",
        "           fontsize='large')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbeLYCp2k5hl"
      },
      "outputs": [],
      "source": [
        "# split train/val set randomly\n",
        "split_dir = 'splits'\n",
        "mmengine.mkdir_or_exist(osp.join(data_root, split_dir))\n",
        "filename_list = [osp.splitext(filename)[0] for filename in mmengine.scandir(\n",
        "    osp.join(data_root, ann_dir), suffix='.png')]\n",
        "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
        "  # select first 4/5 as train set\n",
        "  train_length = int(len(filename_list)*4/5)\n",
        "  f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
        "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
        "  # select last 1/5 as train set\n",
        "  f.writelines(line + '\\n' for line in filename_list[train_length:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HchvmGYB_rrO"
      },
      "source": [
        "After downloading the data, we need to implement `load_annotations` function in the new dataset class `StanfordBackgroundDataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbsWOw62_o-X"
      },
      "outputs": [],
      "source": [
        "from mmseg.registry import DATASETS\n",
        "from mmseg.datasets import BaseSegDataset\n",
        "\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class StanfordBackgroundDataset(BaseSegDataset):\n",
        "  METAINFO = dict(classes = classes, palette = palette)\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(img_suffix='.jpg', seg_map_suffix='.png', **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUVtmn3Iq3WA"
      },
      "source": [
        "### Create a config file\n",
        "In the next step, we need to modify the config for the training. To accelerate the process, we finetune the model from trained weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXUB89I2fPDV",
        "outputId": "d84a3685-c28b-483c-ffe6-658012ba6fd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing mobilenet-v3-d8_lraspp_4xb4-320k_cityscapes-512x1024...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MiB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded lraspp_m-v3-d8_512x1024_320k_cityscapes_20201224_220337-cfe8fb07.pth to /content/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped mobilenet-v3-d8_lraspp_4xb4-320k_cityscapes-512x1024.py to /content/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Download config and checkpoint files\n",
        "!mim download mmsegmentation --config mobilenet-v3-d8_lraspp_4xb4-320k_cityscapes-512x1024 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wwnj9tRzqX_A",
        "outputId": "8f309b48-9684-4861-83c3-36dceff8b4cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    1024,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        1024,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = 'data/cityscapes/'\n",
            "dataset_type = 'CityscapesDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),\n",
            "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = None\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        arch='large',\n",
            "        norm_cfg=dict(eps=0.001, requires_grad=True, type='SyncBN'),\n",
            "        out_indices=(\n",
            "            1,\n",
            "            3,\n",
            "            16,\n",
            "        ),\n",
            "        type='MobileNetV3'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            1024,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        align_corners=False,\n",
            "        channels=128,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=(\n",
            "            16,\n",
            "            24,\n",
            "            960,\n",
            "        ),\n",
            "        in_index=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "        ),\n",
            "        input_transform='multiple_select',\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(eps=0.001, requires_grad=True, type='SyncBN'),\n",
            "        num_classes=19,\n",
            "        type='LRASPPHead'),\n",
            "    pretrained='open-mmlab://contrib/mobilenet_v3_large',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(eps=0.001, requires_grad=True, type='SyncBN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=160000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "resume = False\n",
            "runner = dict(max_iters=320000, type='IterBasedRunner')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2048,\n",
            "                1024,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        2048,\n",
            "        1024,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)\n",
            "train_dataloader = dict(\n",
            "    batch_size=4,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/train', seg_map_path='gtFine/train'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(\n",
            "                keep_ratio=True,\n",
            "                ratio_range=(\n",
            "                    0.5,\n",
            "                    2.0,\n",
            "                ),\n",
            "                scale=(\n",
            "                    2048,\n",
            "                    1024,\n",
            "                ),\n",
            "                type='RandomResize'),\n",
            "            dict(\n",
            "                cat_max_ratio=0.75, crop_size=(\n",
            "                    512,\n",
            "                    1024,\n",
            "                ), type='RandomCrop'),\n",
            "            dict(prob=0.5, type='RandomFlip'),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(\n",
            "        keep_ratio=True,\n",
            "        ratio_range=(\n",
            "            0.5,\n",
            "            2.0,\n",
            "        ),\n",
            "        scale=(\n",
            "            2048,\n",
            "            1024,\n",
            "        ),\n",
            "        type='RandomResize'),\n",
            "    dict(cat_max_ratio=0.75, crop_size=(\n",
            "        512,\n",
            "        1024,\n",
            "    ), type='RandomCrop'),\n",
            "    dict(prob=0.5, type='RandomFlip'),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        data_prefix=dict(\n",
            "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
            "        data_root='data/cityscapes/',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                2048,\n",
            "                1024,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='CityscapesDataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from mmengine import Config\n",
        "cfg = Config.fromfile('configs/mobilenet_v3/mobilenet-v3-d8_lraspp_4xb4-320k_cityscapes-512x1024.py')\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y2oV5w97jQo"
      },
      "source": [
        "Since the given config is used to train PSPNet on the cityscapes dataset, we need to modify it accordingly for our new dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqY0AnpKgWEc",
        "outputId": "23348312-0bf2-413a-9590-00d280fdda15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.1.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.12)\n"
          ]
        }
      ],
      "source": [
        "! pip install ftfy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "q3KOcgSNfa2r"
      },
      "outputs": [],
      "source": [
        "from mmseg.registry import DATASETS\n",
        "from mmseg.datasets import BaseSegDataset\n",
        "\n",
        "root = '/content/data'\n",
        "img_dir = 'image_png'\n",
        "ann_dir = 'fluid_png'\n",
        "\n",
        "classes = ('image', 'fluid')\n",
        "\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class BOE_Chiu_Dataset(BaseSegDataset):\n",
        "    METAINFO = dict(classes = classes)\n",
        "    def __init__(self,dataset=None, times=None, **kwargs):\n",
        "        super(BOE_Chiu_Dataset, self).__init__(img_suffix='.png', seg_map_suffix='.png', **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLChYYowhGUm",
        "outputId": "3840492d-5c82-4a38-c922-2067cb0b9855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0+cu118\n",
            "1.2.1\n"
          ]
        }
      ],
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__)\n",
        "assert torch.cuda.is_available() == True, \"GPU is not available\"\n",
        "\n",
        "import mmseg\n",
        "print(mmseg.__version__)\n",
        "\n",
        "import mmcv\n",
        "import mmengine\n",
        "from mmseg.registry import DATASETS\n",
        "from mmseg.datasets import BaseSegDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SloNYWggiqL",
        "outputId": "b3c1b40e-1af6-4b3a-e6c9-a830ea59a694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    1024,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        1024,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/content/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/content/checkpoint/lraspp_m-v3-d8_512x1024_320k_cityscapes_20201224_220337-cfe8fb07.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        arch='large',\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        out_indices=(\n",
            "            1,\n",
            "            3,\n",
            "            16,\n",
            "        ),\n",
            "        type='MobileNetV3'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            1024,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        align_corners=False,\n",
            "        channels=128,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=(\n",
            "            16,\n",
            "            24,\n",
            "            960,\n",
            "        ),\n",
            "        in_index=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "        ),\n",
            "        input_transform='multiple_select',\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='LRASPPHead'),\n",
            "    pretrained='open-mmlab://contrib/mobilenet_v3_large',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=160000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "runner = dict(max_iters=320000, type='IterBasedRunner')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='/content/splits/val.txt',\n",
            "        data_prefix=dict(img_path='image_png', seg_map_path='fluid_png'),\n",
            "        data_root='/content/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=4,\n",
            "    dataset=dict(\n",
            "        ann_file='/content/splits/train.txt',\n",
            "        data_prefix=dict(img_path='image_png', seg_map_path='fluid_png'),\n",
            "        data_root='/content/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='/content/splits/val.txt',\n",
            "        data_prefix=dict(img_path='image_png', seg_map_path='fluid_png'),\n",
            "        data_root='/content/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#from mmcv import Config\n",
        "cfg = mmengine.Config.fromfile('configs/mobilenet_v3/mobilenet-v3-d8_lraspp_4xb4-320k_cityscapes-512x1024.py')\n",
        "\n",
        "# # make dir checkpoint if not exist\n",
        "# !mkdir checkpoint\n",
        "# !wget https://download.openmmlab.com/mmsegmentation/v0.5/mobilenet_v3/lraspp_m-v3-d8_512x1024_320k_cityscapes/lraspp_m-v3-d8_512x1024_320k_cityscapes_20201224_220337-cfe8fb07.pth\n",
        "\n",
        "\n",
        "# from mmseg.apis import set_random_seed\n",
        "# from mmseg.utils import get_device\n",
        "\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "# cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 2\n",
        "# cfg.model.auxiliary_head.num_classes = 2\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = 'BOE_Chiu_Dataset'\n",
        "cfg.data_root = root\n",
        "\n",
        "# cfg.data.samples_per_gpu = 8\n",
        "# cfg.data.workers_per_gpu=8\n",
        "# cfg.crop_size = (256, 256)\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='Resize', scale=(512, 512), keep_ratio=True),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='Resize', scale=(512, 512), keep_ratio=True),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.train_dataloader.dataset.data_prefix = dict(img_path=img_dir, seg_map_path=ann_dir)\n",
        "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "cfg.train_dataloader.dataset.ann_file = '/content/splits/train.txt'\n",
        "\n",
        "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.val_dataloader.dataset.data_prefix = dict(img_path=img_dir, seg_map_path=ann_dir)\n",
        "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "cfg.val_dataloader.dataset.ann_file = '/content/splits/val.txt'\n",
        "\n",
        "cfg.test_dataloader = cfg.val_dataloader\n",
        "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
        "# use the mask branch\n",
        "cfg.load_from = '/content/checkpoint/lraspp_m-v3-d8_512x1024_320k_cityscapes_20201224_220337-cfe8fb07.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.train_cfg.max_iters = 200\n",
        "cfg.train_cfg.val_interval = 200\n",
        "cfg.default_hooks.logger.interval = 10\n",
        "cfg.default_hooks.checkpoint.interval = 200\n",
        "\n",
        "# Set seed to facitate reproducing the result\n",
        "cfg['randomness'] = dict(seed=0)\n",
        "\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyKnYC1Z7iCV"
      },
      "outputs": [],
      "source": [
        "# # Since we use only one GPU, BN is used instead of SyncBN\n",
        "# cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "# cfg.crop_size = (256, 256)\n",
        "# cfg.model.data_preprocessor.size = cfg.crop_size\n",
        "# cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "# cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "# cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# # modify num classes of the model in decode/auxiliary head\n",
        "# cfg.model.decode_head.num_classes = 8\n",
        "# cfg.model.auxiliary_head.num_classes = 8\n",
        "\n",
        "# # Modify dataset type and path\n",
        "# cfg.dataset_type = 'StanfordBackgroundDataset'\n",
        "# cfg.data_root = data_root\n",
        "\n",
        "# cfg.train_dataloader.batch_size = 8\n",
        "\n",
        "# cfg.train_pipeline = [\n",
        "#     dict(type='LoadImageFromFile'),\n",
        "#     dict(type='LoadAnnotations'),\n",
        "#     dict(type='RandomResize', scale=(320, 240), ratio_range=(0.5, 2.0), keep_ratio=True),\n",
        "#     dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "#     dict(type='RandomFlip', prob=0.5),\n",
        "#     dict(type='PackSegInputs')\n",
        "# ]\n",
        "\n",
        "# cfg.test_pipeline = [\n",
        "#     dict(type='LoadImageFromFile'),\n",
        "#     dict(type='Resize', scale=(320, 240), keep_ratio=True),\n",
        "#     # add loading annotation after ``Resize`` because ground truth\n",
        "#     # does not need to do resize data transform\n",
        "#     dict(type='LoadAnnotations'),\n",
        "#     dict(type='PackSegInputs')\n",
        "# ]\n",
        "\n",
        "\n",
        "# cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "# cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "# cfg.train_dataloader.dataset.data_prefix = dict(img_path=img_dir, seg_map_path=ann_dir)\n",
        "# cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "# cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
        "\n",
        "# cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "# cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "# cfg.val_dataloader.dataset.data_prefix = dict(img_path=img_dir, seg_map_path=ann_dir)\n",
        "# cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "# cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
        "\n",
        "# cfg.test_dataloader = cfg.val_dataloader\n",
        "\n",
        "\n",
        "# # Load the pretrained weights\n",
        "# cfg.load_from = 'pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
        "\n",
        "# # Set up working dir to save files and logs.\n",
        "# cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "# cfg.train_cfg.max_iters = 200\n",
        "# cfg.train_cfg.val_interval = 200\n",
        "# cfg.default_hooks.logger.interval = 10\n",
        "# cfg.default_hooks.checkpoint.interval = 200\n",
        "\n",
        "# # Set seed to facilitate reproducing the result\n",
        "# cfg['randomness'] = dict(seed=0)\n",
        "\n",
        "# # Let's have a look at the final config used for training\n",
        "# print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWuH14LYF2gQ"
      },
      "source": [
        "### Train and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYKoSfdMF12B",
        "outputId": "4e487bbe-d438-4926-a6b8-8147a304d75a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/11 02:05:25 - mmengine - INFO - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.1.0+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.0+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/11 02:05:25 - mmengine - INFO - Config:\n",
            "crop_size = (\n",
            "    512,\n",
            "    1024,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        512,\n",
            "        1024,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/content/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "load_from = '/content/checkpoint/lraspp_m-v3-d8_512x1024_320k_cityscapes_20201224_220337-cfe8fb07.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        arch='large',\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        out_indices=(\n",
            "            1,\n",
            "            3,\n",
            "            16,\n",
            "        ),\n",
            "        type='MobileNetV3'),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            512,\n",
            "            1024,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        align_corners=False,\n",
            "        channels=128,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=(\n",
            "            16,\n",
            "            24,\n",
            "            960,\n",
            "        ),\n",
            "        in_index=(\n",
            "            0,\n",
            "            1,\n",
            "            2,\n",
            "        ),\n",
            "        input_transform='multiple_select',\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='LRASPPHead'),\n",
            "    pretrained='open-mmlab://contrib/mobilenet_v3_large',\n",
            "    test_cfg=dict(mode='whole'),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=160000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "runner = dict(max_iters=320000, type='IterBasedRunner')\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='/content/splits/val.txt',\n",
            "        data_prefix=dict(img_path='image_png', seg_map_path='fluid_png'),\n",
            "        data_root='/content/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=4,\n",
            "    dataset=dict(\n",
            "        ann_file='/content/splits/train.txt',\n",
            "        data_prefix=dict(img_path='image_png', seg_map_path='fluid_png'),\n",
            "        data_root='/content/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='/content/splits/val.txt',\n",
            "        data_prefix=dict(img_path='image_png', seg_map_path='fluid_png'),\n",
            "        data_root='/content/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mIoU',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n",
            "/content/mmsegmentation/mmseg/models/backbones/mobilenet_v3.py:90: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n",
            "  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n",
            "/usr/local/lib/python3.10/dist-packages/mmcv/cnn/bricks/hsigmoid.py:35: UserWarning: In MMCV v1.4.4, we modified the default value of args to align with PyTorch official. Previous Implementation: Hsigmoid(x) = min(max((x + 1) / 2, 0), 1). Current Implementation: Hsigmoid(x) = min(max((x + 3) / 6, 0), 1).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/11 02:05:26 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/11 02:05:26 - mmengine - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmsegmentation/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/content/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/content/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        }
      ],
      "source": [
        "from mmengine.runner import Runner\n",
        "\n",
        "runner = Runner.from_cfg(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "GYdSuoHMfPDW",
        "outputId": "b18de4b0-8a01-434f-99e3-dd17f8ada7de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/11 02:05:50 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.\n",
            "12/11 02:05:50 - mmengine - INFO - load model from: open-mmlab://contrib/mobilenet_v3_large\n",
            "12/11 02:05:50 - mmengine - INFO - Loads checkpoint by openmmlab backend from path: open-mmlab://contrib/mobilenet_v3_large\n",
            "Loads checkpoint by local backend from path: /content/checkpoint/lraspp_m-v3-d8_512x1024_320k_cityscapes_20201224_220337-cfe8fb07.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for decode_head.conv_seg.weight: copying a param with shape torch.Size([19, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 128, 1, 1]).\n",
            "size mismatch for decode_head.conv_seg.bias: copying a param with shape torch.Size([19]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/11 02:05:51 - mmengine - INFO - Load checkpoint from /content/checkpoint/lraspp_m-v3-d8_512x1024_320k_cityscapes_20201224_220337-cfe8fb07.pth\n",
            "12/11 02:05:51 - mmengine - WARNING - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/11 02:05:51 - mmengine - INFO - Checkpoints will be saved to /content/mmsegmentation/work_dirs/tutorial.\n",
            "12/11 02:06:11 - mmengine - INFO - Iter(train) [ 10/200]  lr: 9.9995e-03  eta: 0:06:34  time: 2.0781  data_time: 0.0120  memory: 12914  loss: 0.1110  decode.loss_ce: 0.1110  decode.acc_seg: 100.0000\n",
            "12/11 02:06:16 - mmengine - INFO - Iter(train) [ 20/200]  lr: 9.9989e-03  eta: 0:03:48  time: 0.4651  data_time: 0.0124  memory: 7590  loss: 0.0059  decode.loss_ce: 0.0059  decode.acc_seg: 100.0000\n",
            "12/11 02:06:17 - mmengine - INFO - Exp name: mobilenet-v3-d8_lraspp_4xb4-320k_cityscapes-512x1024_20231211_020525\n",
            "12/11 02:06:21 - mmengine - INFO - Iter(train) [ 30/200]  lr: 9.9984e-03  eta: 0:02:51  time: 0.4762  data_time: 0.0153  memory: 7590  loss: 0.0009  decode.loss_ce: 0.0009  decode.acc_seg: 100.0000\n",
            "12/11 02:06:25 - mmengine - INFO - Iter(train) [ 40/200]  lr: 9.9978e-03  eta: 0:02:19  time: 0.4674  data_time: 0.0111  memory: 7590  loss: 0.0004  decode.loss_ce: 0.0004  decode.acc_seg: 100.0000\n",
            "12/11 02:06:30 - mmengine - INFO - Iter(train) [ 50/200]  lr: 9.9973e-03  eta: 0:01:58  time: 0.4730  data_time: 0.0145  memory: 7590  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000\n",
            "12/11 02:06:35 - mmengine - INFO - Iter(train) [ 60/200]  lr: 9.9967e-03  eta: 0:01:43  time: 0.4664  data_time: 0.0093  memory: 7590  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000\n",
            "12/11 02:06:40 - mmengine - INFO - Iter(train) [ 70/200]  lr: 9.9962e-03  eta: 0:01:30  time: 0.4737  data_time: 0.0104  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:06:44 - mmengine - INFO - Iter(train) [ 80/200]  lr: 9.9956e-03  eta: 0:01:20  time: 0.4848  data_time: 0.0159  memory: 7590  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000\n",
            "12/11 02:06:49 - mmengine - INFO - Iter(train) [ 90/200]  lr: 9.9950e-03  eta: 0:01:11  time: 0.4770  data_time: 0.0089  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:06:54 - mmengine - INFO - Iter(train) [100/200]  lr: 9.9945e-03  eta: 0:01:03  time: 0.4817  data_time: 0.0109  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:06:59 - mmengine - INFO - Iter(train) [110/200]  lr: 9.9939e-03  eta: 0:00:55  time: 0.4883  data_time: 0.0124  memory: 7590  loss: 0.0003  decode.loss_ce: 0.0003  decode.acc_seg: 100.0000\n",
            "12/11 02:07:04 - mmengine - INFO - Iter(train) [120/200]  lr: 9.9934e-03  eta: 0:00:48  time: 0.4865  data_time: 0.0088  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:07:09 - mmengine - INFO - Iter(train) [130/200]  lr: 9.9928e-03  eta: 0:00:42  time: 0.4928  data_time: 0.0113  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:07:14 - mmengine - INFO - Iter(train) [140/200]  lr: 9.9923e-03  eta: 0:00:35  time: 0.4992  data_time: 0.0139  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:07:19 - mmengine - INFO - Iter(train) [150/200]  lr: 9.9917e-03  eta: 0:00:29  time: 0.4952  data_time: 0.0097  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:07:24 - mmengine - INFO - Iter(train) [160/200]  lr: 9.9911e-03  eta: 0:00:23  time: 0.5064  data_time: 0.0142  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:07:29 - mmengine - INFO - Iter(train) [170/200]  lr: 9.9906e-03  eta: 0:00:17  time: 0.5091  data_time: 0.0114  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:07:34 - mmengine - INFO - Iter(train) [180/200]  lr: 9.9900e-03  eta: 0:00:11  time: 0.5068  data_time: 0.0095  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:07:39 - mmengine - INFO - Iter(train) [190/200]  lr: 9.9895e-03  eta: 0:00:05  time: 0.5190  data_time: 0.0143  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:07:44 - mmengine - INFO - Iter(train) [200/200]  lr: 9.9889e-03  eta: 0:00:00  time: 0.5201  data_time: 0.0149  memory: 7590  loss: 0.0002  decode.loss_ce: 0.0002  decode.acc_seg: 100.0000\n",
            "12/11 02:07:44 - mmengine - INFO - Saving checkpoint at 200 iterations\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9bb7b6cec157>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1777\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1778\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_run'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_begin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     and self._iter % self.val_interval == 0):\n\u001b[0;32m--> 284\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;31m# compute metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\u001b[0m in \u001b[0;36mrun_iter\u001b[0;34m(self, idx, data_batch)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;31m# outputs should be sequence of BaseDataElement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         self.runner.call_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\u001b[0m in \u001b[0;36mval_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \"\"\"\n\u001b[1;32m    132\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \"\"\"\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, data_samples, mode)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensor'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs, data_samples)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ] * inputs.shape[0]\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mseg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, inputs, batch_img_metas)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mseg_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslide_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mseg_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhole_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseg_logit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36mwhole_inference\u001b[0;34m(self, inputs, batch_img_metas)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mseg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseg_logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36mencode_decode\u001b[0;34m(self, inputs, batch_img_metas)\u001b[0m\n\u001b[1;32m    127\u001b[0m         map of the same size as input.\"\"\"\n\u001b[1;32m    128\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         seg_logits = self.decode_head.predict(x, batch_img_metas,\n\u001b[0m\u001b[1;32m    130\u001b[0m                                               self.test_cfg)\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/decode_heads/decode_head.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs, batch_img_metas, test_cfg)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutputs\u001b[0m \u001b[0msegmentation\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mseg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_by_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/decode_heads/lraspp_head.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         x = self.aspp_conv(x) * resize(\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         return F.avg_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    636\u001b[0m                             self.padding, self.ceil_mode, self.count_include_pad, self.divisor_override)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (960x42x64). Calculated output size: (960x0x1). Output size is too small"
          ]
        }
      ],
      "source": [
        "# start training\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEkWOP-NMbc_"
      },
      "source": [
        "Inference with trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "ekG__UfaH_OU",
        "outputId": "45bdd815-13da-48da-a859-73a7ddb8e40b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mmcv/cnn/bricks/hsigmoid.py:35: UserWarning: In MMCV v1.4.4, we modified the default value of args to align with PyTorch official. Previous Implementation: Hsigmoid(x) = min(max((x + 1) / 2, 0), 1). Current Implementation: Hsigmoid(x) = min(max((x + 3) / 6, 0), 1).\n",
            "  warnings.warn(\n",
            "/content/mmsegmentation/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/content/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loads checkpoint by local backend from path: ./work_dirs/tutorial/iter_200.pth\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5bf863083b82>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data/image_png/img_0.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvis_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_result_pyplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/apis/inference.py\u001b[0m in \u001b[0;36minference_model\u001b[0;34m(model, img)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# forward the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_batch\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[1;32m    144\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     def parse_losses(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \"\"\"\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, data_samples, mode)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensor'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs, data_samples)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ] * inputs.shape[0]\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mseg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, inputs, batch_img_metas)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mseg_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslide_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mseg_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhole_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseg_logit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36mwhole_inference\u001b[0;34m(self, inputs, batch_img_metas)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mseg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseg_logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/segmentors/encoder_decoder.py\u001b[0m in \u001b[0;36mencode_decode\u001b[0;34m(self, inputs, batch_img_metas)\u001b[0m\n\u001b[1;32m    127\u001b[0m         map of the same size as input.\"\"\"\n\u001b[1;32m    128\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         seg_logits = self.decode_head.predict(x, batch_img_metas,\n\u001b[0m\u001b[1;32m    130\u001b[0m                                               self.test_cfg)\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/decode_heads/decode_head.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs, batch_img_metas, test_cfg)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutputs\u001b[0m \u001b[0msegmentation\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mseg_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_by_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_img_metas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmsegmentation/mmseg/models/decode_heads/lraspp_head.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         x = self.aspp_conv(x) * resize(\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         return F.avg_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    636\u001b[0m                             self.padding, self.ceil_mode, self.count_include_pad, self.divisor_override)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (960x42x64). Calculated output size: (960x0x1). Output size is too small"
          ]
        }
      ],
      "source": [
        "from mmseg.apis import init_model, inference_model, show_result_pyplot\n",
        "\n",
        "# Init the model from the config and the checkpoint\n",
        "checkpoint_path = './work_dirs/tutorial/iter_200.pth'\n",
        "model = init_model(cfg, checkpoint_path, 'cuda:0')\n",
        "\n",
        "img = mmcv.imread('/content/data/image_png/img_0.png')\n",
        "result = inference_model(model, img)\n",
        "plt.figure(figsize=(8, 6))\n",
        "vis_result = show_result_pyplot(model, img, result)\n",
        "plt.imshow(mmcv.bgr2rgb(vis_result))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJvHeSb2onE1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "AcZg6x_K5Zs3"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('pt1.12')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "0442e67aee3d9cbb788fa6e86d60c4ffa94ad7f1943c65abfecb99a6f4696c58"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
