{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "from pretrained_model import *\n",
        "from mmseg.registry import DATASETS\n",
        "from mmseg.datasets import BaseSegDataset\n",
        "%cd mmsegmentation\n",
        "\n",
        "root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
        "img_dir = 'image_png_256_gray'\n",
        "ann_dir = 'fluid_png_256_binary'\n",
        "\n",
        "classes = ('image', 'fluid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "@DATASETS.register_module()\n",
        "class BOE_Chiu_Dataset(BaseSegDataset):\n",
        "    METAINFO = dict(classes = classes)\n",
        "    def __init__(self,dataset=None, times=None, **kwargs):\n",
        "        super(BOE_Chiu_Dataset, self).__init__(img_suffix='.png', seg_map_suffix='.png', **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. UNET with FCN Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mim download mmsegmentation --config unet-s5-d16_fcn_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version:2.1.1+cu121, \n",
            "GPU In-Use: True\n",
            "MMSegmentation Version:1.2.1\n",
            "Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n",
            "12/13 19:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/13 19:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/13 19:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/13 19:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/13 19:01:41 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth\n",
            "12/13 19:01:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth\n",
            "12/13 19:01:41 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/13 19:01:41 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "12/13 19:01:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/13 19:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:02:05  time: 0.6583  data_time: 0.0039  memory: 10544  loss: 0.0798  decode.loss_ce: 0.0571  decode.acc_seg: 99.2973  aux.loss_ce: 0.0227  aux.acc_seg: 99.2973\n",
            "12/13 19:01:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:15  time: 0.1832  data_time: 0.0043  memory: 4702  loss: 0.0402  decode.loss_ce: 0.0276  decode.acc_seg: 99.8108  aux.loss_ce: 0.0127  aux.acc_seg: 99.8108\n",
            "12/13 19:01:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:00:58  time: 0.1846  data_time: 0.0045  memory: 4702  loss: 0.0426  decode.loss_ce: 0.0299  decode.acc_seg: 99.9931  aux.loss_ce: 0.0126  aux.acc_seg: 99.9931\n",
            "12/13 19:01:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:00:48  time: 0.1835  data_time: 0.0043  memory: 4702  loss: 0.0296  decode.loss_ce: 0.0203  decode.acc_seg: 99.3652  aux.loss_ce: 0.0093  aux.acc_seg: 99.3652\n",
            "12/13 19:01:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_fcn_4xb4-40k_hrf-256x256_20231213_190137\n",
            "12/13 19:01:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:00:41  time: 0.1841  data_time: 0.0044  memory: 4702  loss: 0.0242  decode.loss_ce: 0.0160  decode.acc_seg: 98.8808  aux.loss_ce: 0.0082  aux.acc_seg: 98.8808\n",
            "12/13 19:01:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:00:36  time: 0.1837  data_time: 0.0043  memory: 4702  loss: 0.0328  decode.loss_ce: 0.0229  decode.acc_seg: 99.7147  aux.loss_ce: 0.0099  aux.acc_seg: 99.7147\n",
            "12/13 19:01:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:00:32  time: 0.1848  data_time: 0.0045  memory: 4702  loss: 0.0220  decode.loss_ce: 0.0149  decode.acc_seg: 99.9893  aux.loss_ce: 0.0071  aux.acc_seg: 99.9893\n",
            "12/13 19:02:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:29  time: 0.1828  data_time: 0.0043  memory: 4702  loss: 0.0219  decode.loss_ce: 0.0150  decode.acc_seg: 100.0000  aux.loss_ce: 0.0069  aux.acc_seg: 100.0000\n",
            "12/13 19:02:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:26  time: 0.1861  data_time: 0.0044  memory: 4702  loss: 0.0240  decode.loss_ce: 0.0165  decode.acc_seg: 99.7917  aux.loss_ce: 0.0074  aux.acc_seg: 99.7917\n",
            "12/13 19:02:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:23  time: 0.1844  data_time: 0.0042  memory: 4702  loss: 0.0205  decode.loss_ce: 0.0139  decode.acc_seg: 99.8444  aux.loss_ce: 0.0066  aux.acc_seg: 99.8718\n",
            "12/13 19:02:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:20  time: 0.1836  data_time: 0.0042  memory: 4702  loss: 0.0189  decode.loss_ce: 0.0126  decode.acc_seg: 99.9031  aux.loss_ce: 0.0063  aux.acc_seg: 99.8875\n",
            "12/13 19:02:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:17  time: 0.1855  data_time: 0.0043  memory: 4702  loss: 0.0138  decode.loss_ce: 0.0088  decode.acc_seg: 99.7910  aux.loss_ce: 0.0050  aux.acc_seg: 99.7910\n",
            "12/13 19:02:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:15  time: 0.1855  data_time: 0.0044  memory: 4702  loss: 0.0160  decode.loss_ce: 0.0106  decode.acc_seg: 99.9405  aux.loss_ce: 0.0055  aux.acc_seg: 99.9475\n",
            "12/13 19:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:13  time: 0.1841  data_time: 0.0042  memory: 4702  loss: 0.0156  decode.loss_ce: 0.0102  decode.acc_seg: 99.5186  aux.loss_ce: 0.0054  aux.acc_seg: 99.5186\n",
            "12/13 19:02:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:10  time: 0.1842  data_time: 0.0043  memory: 4702  loss: 0.0168  decode.loss_ce: 0.0112  decode.acc_seg: 99.7955  aux.loss_ce: 0.0056  aux.acc_seg: 99.7540\n",
            "12/13 19:02:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:08  time: 0.1851  data_time: 0.0042  memory: 4702  loss: 0.0181  decode.loss_ce: 0.0120  decode.acc_seg: 99.3774  aux.loss_ce: 0.0060  aux.acc_seg: 99.4020\n",
            "12/13 19:02:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:06  time: 0.1852  data_time: 0.0043  memory: 4702  loss: 0.0135  decode.loss_ce: 0.0089  decode.acc_seg: 99.9466  aux.loss_ce: 0.0045  aux.acc_seg: 99.9460\n",
            "12/13 19:02:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:04  time: 0.1846  data_time: 0.0044  memory: 4702  loss: 0.0102  decode.loss_ce: 0.0068  decode.acc_seg: 99.7597  aux.loss_ce: 0.0035  aux.acc_seg: 99.7593\n",
            "12/13 19:02:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:02  time: 0.1846  data_time: 0.0045  memory: 4702  loss: 0.0102  decode.loss_ce: 0.0065  decode.acc_seg: 99.9550  aux.loss_ce: 0.0037  aux.acc_seg: 99.9489\n",
            "12/13 19:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.1850  data_time: 0.0043  memory: 4702  loss: 0.0210  decode.loss_ce: 0.0144  decode.acc_seg: 100.0000  aux.loss_ce: 0.0066  aux.acc_seg: 100.0000\n",
            "12/13 19:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/13 19:02:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:03  time: 0.3106  data_time: 0.0131  memory: 9010  \n",
            "12/13 19:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1245  data_time: 0.0025  memory: 372  \n",
            "12/13 19:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/13 19:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+\n",
            "| Class |  Dice |  Acc  |\n",
            "+-------+-------+-------+\n",
            "| image | 99.73 | 100.0 |\n",
            "| fluid |  0.0  |  0.0  |\n",
            "+-------+-------+-------+\n",
            "12/13 19:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 49.8700  mAcc: 50.0000  data_time: 0.0073  time: 0.2089\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_fcn_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/fcn_unet_s5-d16_256x256_40k_hrf_20201223_173724-d89cf1ed.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. UNET with PSP Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing unet-s5-d16_pspnet_4xb4-40k_hrf-256x256...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.9/110.9 MiB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped unet-s5-d16_pspnet_4xb4-40k_hrf-256x256.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!mim download mmsegmentation --config unet-s5-d16_pspnet_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/13 19:29:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/13 19:30:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=16,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        pool_scales=(\n",
            "            1,\n",
            "            2,\n",
            "            3,\n",
            "            6,\n",
            "        ),\n",
            "        type='PSPHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/13 19:30:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/13 19:30:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/13 19:30:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth\n",
            "12/13 19:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth\n",
            "12/13 19:30:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/13 19:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/13 19:30:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:01:28  time: 0.4667  data_time: 0.0045  memory: 4611  loss: 0.0809  decode.loss_ce: 0.0572  decode.acc_seg: 99.2973  aux.loss_ce: 0.0236  aux.acc_seg: 99.2973\n",
            "12/13 19:30:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:23  time: 0.4614  data_time: 0.0047  memory: 4611  loss: 0.0442  decode.loss_ce: 0.0299  decode.acc_seg: 99.8108  aux.loss_ce: 0.0143  aux.acc_seg: 99.8108\n",
            "12/13 19:30:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:01:18  time: 0.4606  data_time: 0.0046  memory: 4611  loss: 0.0431  decode.loss_ce: 0.0294  decode.acc_seg: 99.9931  aux.loss_ce: 0.0138  aux.acc_seg: 99.9931\n",
            "12/13 19:30:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:01:13  time: 0.4610  data_time: 0.0046  memory: 4611  loss: 0.0337  decode.loss_ce: 0.0238  decode.acc_seg: 99.3652  aux.loss_ce: 0.0099  aux.acc_seg: 99.3652\n",
            "12/13 19:30:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_pspnet_4xb4-40k_hrf-256x256_20231213_192930\n",
            "12/13 19:30:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:01:09  time: 0.4624  data_time: 0.0050  memory: 4611  loss: 0.0251  decode.loss_ce: 0.0175  decode.acc_seg: 98.8808  aux.loss_ce: 0.0076  aux.acc_seg: 98.8808\n",
            "12/13 19:30:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:01:04  time: 0.4635  data_time: 0.0047  memory: 4611  loss: 0.0339  decode.loss_ce: 0.0239  decode.acc_seg: 99.7168  aux.loss_ce: 0.0100  aux.acc_seg: 99.7147\n",
            "12/13 19:30:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:01:00  time: 0.4629  data_time: 0.0047  memory: 4611  loss: 0.0213  decode.loss_ce: 0.0143  decode.acc_seg: 99.9893  aux.loss_ce: 0.0070  aux.acc_seg: 99.9893\n",
            "12/13 19:30:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:55  time: 0.4603  data_time: 0.0047  memory: 4611  loss: 0.0242  decode.loss_ce: 0.0159  decode.acc_seg: 100.0000  aux.loss_ce: 0.0082  aux.acc_seg: 100.0000\n",
            "12/13 19:30:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:50  time: 0.4608  data_time: 0.0046  memory: 4611  loss: 0.0238  decode.loss_ce: 0.0160  decode.acc_seg: 99.7917  aux.loss_ce: 0.0078  aux.acc_seg: 99.7917\n",
            "12/13 19:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:46  time: 0.4610  data_time: 0.0047  memory: 4611  loss: 0.0201  decode.loss_ce: 0.0134  decode.acc_seg: 99.7423  aux.loss_ce: 0.0066  aux.acc_seg: 99.8444\n",
            "12/13 19:31:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:41  time: 0.4607  data_time: 0.0046  memory: 4611  loss: 0.0187  decode.loss_ce: 0.0119  decode.acc_seg: 99.9025  aux.loss_ce: 0.0067  aux.acc_seg: 99.9031\n",
            "12/13 19:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:36  time: 0.4604  data_time: 0.0046  memory: 4611  loss: 0.0130  decode.loss_ce: 0.0082  decode.acc_seg: 99.8692  aux.loss_ce: 0.0048  aux.acc_seg: 99.7910\n",
            "12/13 19:31:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:32  time: 0.4618  data_time: 0.0046  memory: 4611  loss: 0.0147  decode.loss_ce: 0.0094  decode.acc_seg: 99.9481  aux.loss_ce: 0.0053  aux.acc_seg: 99.9405\n",
            "12/13 19:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:27  time: 0.4618  data_time: 0.0045  memory: 4611  loss: 0.0157  decode.loss_ce: 0.0102  decode.acc_seg: 99.6630  aux.loss_ce: 0.0055  aux.acc_seg: 99.5186\n",
            "12/13 19:31:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:23  time: 0.4610  data_time: 0.0045  memory: 4611  loss: 0.0151  decode.loss_ce: 0.0095  decode.acc_seg: 99.8106  aux.loss_ce: 0.0056  aux.acc_seg: 99.7993\n",
            "12/13 19:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:18  time: 0.4625  data_time: 0.0047  memory: 4611  loss: 0.0180  decode.loss_ce: 0.0120  decode.acc_seg: 99.5245  aux.loss_ce: 0.0060  aux.acc_seg: 99.3774\n",
            "12/13 19:31:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:13  time: 0.4622  data_time: 0.0047  memory: 4611  loss: 0.0122  decode.loss_ce: 0.0076  decode.acc_seg: 99.9508  aux.loss_ce: 0.0046  aux.acc_seg: 99.9466\n",
            "12/13 19:31:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:09  time: 0.4609  data_time: 0.0046  memory: 4611  loss: 0.0091  decode.loss_ce: 0.0054  decode.acc_seg: 99.7639  aux.loss_ce: 0.0037  aux.acc_seg: 99.7597\n",
            "12/13 19:31:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:04  time: 0.4623  data_time: 0.0046  memory: 4611  loss: 0.0094  decode.loss_ce: 0.0059  decode.acc_seg: 99.9527  aux.loss_ce: 0.0035  aux.acc_seg: 99.9590\n",
            "12/13 19:31:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.4619  data_time: 0.0047  memory: 4611  loss: 0.0184  decode.loss_ce: 0.0117  decode.acc_seg: 100.0000  aux.loss_ce: 0.0066  aux.acc_seg: 100.0000\n",
            "12/13 19:31:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/13 19:31:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.1693  data_time: 0.0131  memory: 403  \n",
            "12/13 19:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1447  data_time: 0.0021  memory: 403  \n",
            "12/13 19:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/13 19:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.73 | 99.98 | 99.47 | 99.73  |   99.49   | 99.98  |\n",
            "| fluid |  7.08 |  3.8  |  3.67 |  7.08  |   50.78   |  3.8   |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/13 19:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.4700  mDice: 53.4000  mAcc: 51.8900  mIoU: 51.5700  mFscore: 53.4000  mPrecision: 75.1300  mRecall: 51.8900  data_time: 0.0071  time: 0.1560\n"
          ]
        }
      ],
      "source": [
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_pspnet_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/pspnet_unet_s5-d16_256x256_40k_hrf_20201227_181818-fdb7e29b.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. UNET with DeepLabV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256...\n",
            "\u001b[2Kdownloading \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 MiB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[32mSuccessfully downloaded deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n",
            "\u001b[32mSuccessfully dumped unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256.py to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!mim download mmsegmentation --config unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256 --dest ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/13 19:27:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla V100-PCIE-16GB\n",
            "    CUDA_HOME: None\n",
            "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
            "    PyTorch: 2.1.1+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.1+cu121\n",
            "    OpenCV: 4.8.1\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: True\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    seed: 0\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/13 19:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "crop_size = (\n",
            "    256,\n",
            "    256,\n",
            ")\n",
            "data_preprocessor = dict(\n",
            "    bgr_to_rgb=True,\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ],\n",
            "    pad_val=0,\n",
            "    seg_pad_val=255,\n",
            "    size=(\n",
            "        256,\n",
            "        256,\n",
            "    ),\n",
            "    std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ],\n",
            "    type='SegDataPreProcessor')\n",
            "data_root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
            "dataset_type = 'BOE_Chiu_Dataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(by_epoch=False, interval=200, type='CheckpointHook'),\n",
            "    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    visualization=dict(type='SegVisualizationHook'))\n",
            "default_scope = 'mmseg'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=True,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_ratios = [\n",
            "    0.5,\n",
            "    0.75,\n",
            "    1.0,\n",
            "    1.25,\n",
            "    1.5,\n",
            "    1.75,\n",
            "]\n",
            "img_scale = (\n",
            "    2336,\n",
            "    3504,\n",
            ")\n",
            "load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=False)\n",
            "model = dict(\n",
            "    auxiliary_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=64,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=128,\n",
            "        in_index=3,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        num_convs=1,\n",
            "        type='FCNHead'),\n",
            "    backbone=dict(\n",
            "        act_cfg=dict(type='ReLU'),\n",
            "        base_channels=64,\n",
            "        conv_cfg=None,\n",
            "        dec_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        dec_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        downsamples=(\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "            True,\n",
            "        ),\n",
            "        enc_dilations=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        enc_num_convs=(\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "            2,\n",
            "        ),\n",
            "        in_channels=3,\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        norm_eval=False,\n",
            "        num_stages=5,\n",
            "        strides=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        type='UNet',\n",
            "        upsample_cfg=dict(type='InterpConv'),\n",
            "        with_cp=False),\n",
            "    data_preprocessor=dict(\n",
            "        bgr_to_rgb=True,\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        pad_val=0,\n",
            "        seg_pad_val=255,\n",
            "        size=(\n",
            "            256,\n",
            "            256,\n",
            "        ),\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='SegDataPreProcessor'),\n",
            "    decode_head=dict(\n",
            "        align_corners=False,\n",
            "        channels=16,\n",
            "        dilations=(\n",
            "            1,\n",
            "            12,\n",
            "            24,\n",
            "            36,\n",
            "        ),\n",
            "        dropout_ratio=0.1,\n",
            "        in_channels=64,\n",
            "        in_index=4,\n",
            "        loss_decode=dict(\n",
            "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
            "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
            "        num_classes=2,\n",
            "        type='ASPPHead'),\n",
            "    pretrained=None,\n",
            "    test_cfg=dict(crop_size=(\n",
            "        256,\n",
            "        256,\n",
            "    ), mode='slide', stride=(\n",
            "        170,\n",
            "        170,\n",
            "    )),\n",
            "    train_cfg=dict(),\n",
            "    type='EncoderDecoder')\n",
            "norm_cfg = dict(requires_grad=True, type='BN')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
            "    type='OptimWrapper')\n",
            "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=False,\n",
            "        end=40000,\n",
            "        eta_min=0.0001,\n",
            "        power=0.9,\n",
            "        type='PolyLR'),\n",
            "]\n",
            "randomness = dict(seed=0)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "    ], type='IoUMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "train_cfg = dict(max_iters=200, type='IterBasedTrainLoop', val_interval=200)\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/train.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        dataset=dict(\n",
            "            data_prefix=dict(\n",
            "                img_path='images/training',\n",
            "                seg_map_path='annotations/training'),\n",
            "            data_root='data/HRF',\n",
            "            pipeline=[\n",
            "                dict(type='LoadImageFromFile'),\n",
            "                dict(type='LoadAnnotations'),\n",
            "                dict(\n",
            "                    keep_ratio=True,\n",
            "                    ratio_range=(\n",
            "                        0.5,\n",
            "                        2.0,\n",
            "                    ),\n",
            "                    scale=(\n",
            "                        2336,\n",
            "                        3504,\n",
            "                    ),\n",
            "                    type='RandomResize'),\n",
            "                dict(\n",
            "                    cat_max_ratio=0.75,\n",
            "                    crop_size=(\n",
            "                        256,\n",
            "                        256,\n",
            "                    ),\n",
            "                    type='RandomCrop'),\n",
            "                dict(prob=0.5, type='RandomFlip'),\n",
            "                dict(type='PhotoMetricDistortion'),\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "            type='HRFDataset'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        times=40000,\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(keep_ratio=True, scale=(\n",
            "        512,\n",
            "        512,\n",
            "    ), type='Resize'),\n",
            "    dict(type='PackSegInputs'),\n",
            "]\n",
            "tta_model = dict(type='SegTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(backend_args=None, type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
            "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
            "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadAnnotations'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='PackSegInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='splits/val.txt',\n",
            "        data_prefix=dict(\n",
            "            img_path='image_png_256_gray',\n",
            "            seg_map_path='fluid_png_256_binary'),\n",
            "        data_root='/workspaces/ECE661GroupProject_TransferLearning/data',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(keep_ratio=True, scale=(\n",
            "                512,\n",
            "                512,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='PackSegInputs'),\n",
            "        ],\n",
            "        type='BOE_Chiu_Dataset'),\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    iou_metrics=[\n",
            "        'mDice',\n",
            "        'mIoU',\n",
            "        'mFscore',\n",
            "    ], type='IoUMetric')\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name='visualizer',\n",
            "    type='SegLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/tutorial'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmseg.visualization.local_visualizer.SegLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/13 19:28:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/13 19:28:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SegVisualizationHook               \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
            "  warnings.warn('For binary segmentation, we suggest using'\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
            "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:249: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/openmmlab/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
            "  warnings.warn('The draw is False, it means that the '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12/13 19:28:04 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
            "Loads checkpoint by local backend from path: /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth\n",
            "12/13 19:28:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth\n",
            "12/13 19:28:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/13 19:28:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/work_dirs/tutorial.\n",
            "12/13 19:28:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 10/200]  lr: 9.9980e-03  eta: 0:01:25  time: 0.4525  data_time: 0.0044  memory: 7822  loss: 0.0893  decode.loss_ce: 0.0629  decode.acc_seg: 99.2973  aux.loss_ce: 0.0264  aux.acc_seg: 99.2973\n",
            "12/13 19:28:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 20/200]  lr: 9.9958e-03  eta: 0:01:07  time: 0.3001  data_time: 0.0050  memory: 4640  loss: 0.0433  decode.loss_ce: 0.0295  decode.acc_seg: 99.8108  aux.loss_ce: 0.0137  aux.acc_seg: 99.8108\n",
            "12/13 19:28:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 30/200]  lr: 9.9935e-03  eta: 0:00:59  time: 0.2972  data_time: 0.0046  memory: 4640  loss: 0.0456  decode.loss_ce: 0.0313  decode.acc_seg: 99.9931  aux.loss_ce: 0.0144  aux.acc_seg: 99.9931\n",
            "12/13 19:28:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 40/200]  lr: 9.9913e-03  eta: 0:00:53  time: 0.2983  data_time: 0.0046  memory: 4640  loss: 0.0336  decode.loss_ce: 0.0233  decode.acc_seg: 99.3652  aux.loss_ce: 0.0103  aux.acc_seg: 99.3652\n",
            "12/13 19:28:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256_20231213_192722\n",
            "12/13 19:28:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 50/200]  lr: 9.9891e-03  eta: 0:00:49  time: 0.2972  data_time: 0.0048  memory: 4640  loss: 0.0288  decode.loss_ce: 0.0206  decode.acc_seg: 98.8808  aux.loss_ce: 0.0082  aux.acc_seg: 98.8808\n",
            "12/13 19:28:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 60/200]  lr: 9.9869e-03  eta: 0:00:45  time: 0.2972  data_time: 0.0047  memory: 4640  loss: 0.0372  decode.loss_ce: 0.0258  decode.acc_seg: 99.7047  aux.loss_ce: 0.0114  aux.acc_seg: 99.7147\n",
            "12/13 19:28:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 70/200]  lr: 9.9846e-03  eta: 0:00:41  time: 0.2996  data_time: 0.0047  memory: 4640  loss: 0.0217  decode.loss_ce: 0.0140  decode.acc_seg: 99.9893  aux.loss_ce: 0.0077  aux.acc_seg: 99.9893\n",
            "12/13 19:28:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 80/200]  lr: 9.9824e-03  eta: 0:00:38  time: 0.3006  data_time: 0.0048  memory: 4640  loss: 0.0248  decode.loss_ce: 0.0165  decode.acc_seg: 100.0000  aux.loss_ce: 0.0084  aux.acc_seg: 100.0000\n",
            "12/13 19:28:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 90/200]  lr: 9.9802e-03  eta: 0:00:34  time: 0.2985  data_time: 0.0046  memory: 4640  loss: 0.0256  decode.loss_ce: 0.0172  decode.acc_seg: 99.4713  aux.loss_ce: 0.0084  aux.acc_seg: 99.7917\n",
            "12/13 19:28:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [100/200]  lr: 9.9779e-03  eta: 0:00:31  time: 0.2990  data_time: 0.0046  memory: 4640  loss: 0.0242  decode.loss_ce: 0.0167  decode.acc_seg: 99.8417  aux.loss_ce: 0.0074  aux.acc_seg: 99.8510\n",
            "12/13 19:28:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [110/200]  lr: 9.9757e-03  eta: 0:00:28  time: 0.3010  data_time: 0.0048  memory: 4640  loss: 0.0183  decode.loss_ce: 0.0119  decode.acc_seg: 99.8825  aux.loss_ce: 0.0065  aux.acc_seg: 99.8852\n",
            "12/13 19:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [120/200]  lr: 9.9735e-03  eta: 0:00:24  time: 0.2979  data_time: 0.0047  memory: 4640  loss: 0.0132  decode.loss_ce: 0.0082  decode.acc_seg: 99.8634  aux.loss_ce: 0.0049  aux.acc_seg: 99.7910\n",
            "12/13 19:28:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [130/200]  lr: 9.9713e-03  eta: 0:00:21  time: 0.2980  data_time: 0.0047  memory: 4640  loss: 0.0155  decode.loss_ce: 0.0097  decode.acc_seg: 99.8543  aux.loss_ce: 0.0058  aux.acc_seg: 99.9369\n",
            "12/13 19:28:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [140/200]  lr: 9.9690e-03  eta: 0:00:18  time: 0.2986  data_time: 0.0047  memory: 4640  loss: 0.0167  decode.loss_ce: 0.0111  decode.acc_seg: 99.6056  aux.loss_ce: 0.0057  aux.acc_seg: 99.5461\n",
            "12/13 19:28:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [150/200]  lr: 9.9668e-03  eta: 0:00:15  time: 0.2970  data_time: 0.0045  memory: 4640  loss: 0.0163  decode.loss_ce: 0.0104  decode.acc_seg: 99.7541  aux.loss_ce: 0.0059  aux.acc_seg: 99.7442\n",
            "12/13 19:28:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [160/200]  lr: 9.9646e-03  eta: 0:00:12  time: 0.2981  data_time: 0.0046  memory: 4640  loss: 0.0184  decode.loss_ce: 0.0125  decode.acc_seg: 99.4974  aux.loss_ce: 0.0059  aux.acc_seg: 99.4833\n",
            "12/13 19:28:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [170/200]  lr: 9.9623e-03  eta: 0:00:09  time: 0.3003  data_time: 0.0047  memory: 4640  loss: 0.0129  decode.loss_ce: 0.0083  decode.acc_seg: 99.9466  aux.loss_ce: 0.0046  aux.acc_seg: 99.9466\n",
            "12/13 19:29:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [180/200]  lr: 9.9601e-03  eta: 0:00:06  time: 0.2984  data_time: 0.0048  memory: 4640  loss: 0.0095  decode.loss_ce: 0.0057  decode.acc_seg: 99.7522  aux.loss_ce: 0.0038  aux.acc_seg: 99.7597\n",
            "12/13 19:29:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [190/200]  lr: 9.9579e-03  eta: 0:00:03  time: 0.2972  data_time: 0.0046  memory: 4640  loss: 0.0097  decode.loss_ce: 0.0060  decode.acc_seg: 99.9563  aux.loss_ce: 0.0037  aux.acc_seg: 99.9603\n",
            "12/13 19:29:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [200/200]  lr: 9.9557e-03  eta: 0:00:00  time: 0.2981  data_time: 0.0046  memory: 4640  loss: 0.0182  decode.loss_ce: 0.0119  decode.acc_seg: 100.0000  aux.loss_ce: 0.0063  aux.acc_seg: 100.0000\n",
            "12/13 19:29:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 200 iterations\n",
            "12/13 19:29:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [10/22]    eta: 0:00:02  time: 0.1697  data_time: 0.0129  memory: 1150  \n",
            "12/13 19:29:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [20/22]    eta: 0:00:00  time: 0.1436  data_time: 0.0022  memory: 394  \n",
            "12/13 19:29:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
            "12/13 19:29:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| Class |  Dice |  Acc  |  IoU  | Fscore | Precision | Recall |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "| image | 99.76 | 99.98 | 99.51 | 99.76  |   99.53   | 99.98  |\n",
            "| fluid |  21.0 | 12.15 | 11.73 |  21.0  |   77.48   | 12.15  |\n",
            "+-------+-------+-------+-------+--------+-----------+--------+\n",
            "12/13 19:29:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [22/22]    aAcc: 99.5100  mDice: 60.3800  mAcc: 56.0600  mIoU: 55.6200  mFscore: 60.3800  mPrecision: 88.5100  mRecall: 56.0600  data_time: 0.0071  time: 0.1556\n"
          ]
        }
      ],
      "source": [
        "\n",
        "config_py_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256.py'\n",
        "pretrained_path = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth'\n",
        "\n",
        "train_model(root, img_dir, ann_dir, config_py_path, pretrained_path, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
