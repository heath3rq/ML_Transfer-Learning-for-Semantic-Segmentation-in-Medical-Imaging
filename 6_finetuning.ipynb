{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import mmseg\n",
    "from mmseg.registry import DATASETS\n",
    "from mmseg.datasets import *\n",
    "import mmcv\n",
    "import mmengine\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from mmengine.runner import Runner\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "%cd mmsegmentation\n",
    "\n",
    "root = '/workspaces/ECE661GroupProject_TransferLearning/data'\n",
    "img_dir = 'image_png_256_gray'\n",
    "ann_dir = 'fluid_png_256_binary'\n",
    "\n",
    "classes = ('image', 'fluid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module()\n",
    "class BOE_Chiu_Dataset(BaseSegDataset):\n",
    "    METAINFO = dict(classes = classes)\n",
    "    def __init__(self,dataset=None, times=None, **kwargs):\n",
    "        super(BOE_Chiu_Dataset, self).__init__(img_suffix='.png', seg_map_suffix='.png', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = mmengine.Config.fromfile('/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/unet-s5-d16_deeplabv3_4xb4-40k_hrf-256x256.py')\n",
    "\n",
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type=\"BN\", requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 2\n",
    "cfg.model.auxiliary_head.num_classes = 2\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = \"BOE_Chiu_Dataset\"\n",
    "cfg.data_root = root\n",
    "\n",
    "cfg.train_dataloader.batch_size = 2\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type=\"LoadImageFromFile\"),\n",
    "    dict(type=\"LoadAnnotations\"),\n",
    "    dict(type=\"Resize\", scale=(512, 512), keep_ratio=True),\n",
    "    dict(type=\"PackSegInputs\"),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type=\"LoadImageFromFile\"),\n",
    "    dict(type=\"Resize\", scale=(512, 512), keep_ratio=True),\n",
    "    dict(type=\"LoadAnnotations\"),\n",
    "    dict(type=\"PackSegInputs\"),\n",
    "]\n",
    "\n",
    "# Configure train dataloader\n",
    "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
    "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.train_dataloader.dataset.data_prefix = dict(\n",
    "    img_path=img_dir, seg_map_path=ann_dir\n",
    ")\n",
    "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
    "cfg.train_dataloader.dataset.ann_file = \"splits/train.txt\"\n",
    "\n",
    "# Configure val & test dataloader\n",
    "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.val_dataloader.dataset.data_prefix = dict(\n",
    "    img_path=img_dir, seg_map_path=ann_dir\n",
    ")\n",
    "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "cfg.val_dataloader.dataset.ann_file = \"splits/val.txt\"\n",
    "\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# Configure Evaluator\n",
    "cfg.test_evaluator = [\"mDice\", \"mIoU\", \"mFscore\"]\n",
    "cfg.val_evaluator.iou_metrics = [\"mDice\", \"mIoU\", \"mFscore\"]\n",
    "\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "cfg.load_from = '/workspaces/ECE661GroupProject_TransferLearning/mmsegmentation/deeplabv3_unet_s5-d16_256x256_40k_hrf_20201226_094047-3a1fdf85.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = \"./work_dirs/tutorial\"\n",
    "\n",
    "cfg.train_cfg.max_iters = 200\n",
    "cfg.train_cfg.val_interval = 200\n",
    "cfg.default_hooks.logger.interval = 10\n",
    "cfg.default_hooks.checkpoint.interval = 200\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.randomness = dict(seed=0)\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f\"Config:\\n{cfg.pretty_text}\")\n",
    "\n",
    "runner = Runner.from_cfg(cfg)\n",
    "\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
